{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "K0U2xhQlhuQy",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<table style=\"text-align: left; width: 100%;\" border=\"0\"\n",
    " cellpadding=\"0\" cellspacing=\"0\">\n",
    "\n",
    "  <tbody>\n",
    "    <tr align=\"center\" style=\"height: 1px; background-color: rgb(0, 0, 0);\">\n",
    "      <td><img src=\"https://i.imgur.com/RGV3U0q.png\" title=\"source: imgur.com\" /></td>\n",
    "      <td><big><big><big><big><span style=\"font-family: Calibri; color: white; font-weight: bold;\">Laboratorio III</span></big></big></big></big></td>\n",
    "      <td><img src=\"https://i.imgur.com/YOQky86.png\" title=\"source: imgur.com\" style=\"width: 250px; height: auto;\" /></td>\n",
    "    </tr>\n",
    "    <tr align=\"center\">\n",
    "      <td colspan=\"3\" rowspan=\"1\"\n",
    " style=\"height: 1px; background-color: rgb(68, 68, 100);\"></td>\n",
    "    </tr>\n",
    "    <tr align=\"center\">\n",
    "      <td colspan=\"3\" rowspan=\"1\"><big><big><big><big><span\n",
    " style=\"font-family: Calibri;\">Grupo7<br> Misc</span></big></big></big></big><br>\n",
    "      </td></tr>\n",
    "    <tr align=\"center\">       \n",
    "      <td colspan=\"3\" rowspan=\"1\" style=\"height: 1px; background-color: rgb(68, 68, 100);\"></td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "\n",
    "<span style=\"font-family: Calibri; font-weight: bold; \">Autores:</span>\n",
    "<br style=\"font-family: Calibri; font-style: italic;\">\n",
    "<span style=\"font-family: Calibri; font-style: italic;\">aDigital</span>\n",
    "<div class=\"footer\">&copy; 2024</div>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# Prediccion Feb 2020: Lectura Completa y Rapida de ventas\n",
    "## Dataset sell-z-780-all-LTSM.csv\n",
    "\n",
    "**Nota:** Este `df_ventas` genera `sell-z-780-all-LTSM.csv` y solo contiene los datos de los 780 productos a predecir.\n",
    "\n",
    "Luego de ejecutar tenemos el `df_ventas` con: \n",
    "- Todas las ventas de los 780 productos a predecir\n",
    "- Matriz de 780 productos * 36 periodos = 28080 (se completaron con 0 los periodos faltantes para cada producto)\n",
    "- Columnas con la clasificacion de productos: cat1, cat2, cat3, brand, sku_size, descripcion\n",
    "- Columna en780 (deberia estar todo en 1 ya que indica que es producto a predecir para febrero 2020)\n",
    "- Columna cant_periodos: contiene para cada producto la cantidad de periodos que tuvo ventas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------\n",
      "Cantidad de NaN x Columna:\n",
      "product_id                  0\n",
      "periodo                     0\n",
      "plan_precios_cuidados    5731\n",
      "cust_request_qty         5731\n",
      "cust_request_tn          5731\n",
      "tn                          0\n",
      "cant_periodos               0\n",
      "cat1                        0\n",
      "cat2                        0\n",
      "cat3                        0\n",
      "brand                       0\n",
      "sku_size                    0\n",
      "descripcion                 0\n",
      "dtype: int64\n",
      "\n",
      "--------------------------------------\n",
      "Completando a 0 los NaN\n",
      "\n",
      "--------------------------------------\n",
      "Cantidad de NaN x Columna:\n",
      "product_id               0\n",
      "periodo                  0\n",
      "plan_precios_cuidados    0\n",
      "cust_request_qty         0\n",
      "cust_request_tn          0\n",
      "tn                       0\n",
      "cant_periodos            0\n",
      "cat1                     0\n",
      "cat2                     0\n",
      "cat3                     0\n",
      "brand                    0\n",
      "sku_size                 0\n",
      "descripcion              0\n",
      "dtype: int64\n",
      "\n",
      "--------------------------------------\n",
      "\n",
      "Generando archivo final: ../66_Datos/sell-z-780-all-LTSM.csv\n",
      "\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar los datos de ventas y productos a predecir\n",
    "#sell-z-780-groupBy-Period-ProdId.csv\n",
    "#ventas_file_path = '../66_Datos/sell-in.txt'\n",
    "ventas_file_path = '../66_Datos/sell-z-780-groupBy-Period-ProdId.csv'\n",
    "productos_file_path = '../66_Datos/productos_a_predecir.txt'\n",
    "productos_descripcion = '../66_Datos/tb_productos_descripcion.txt'\n",
    "\n",
    "\n",
    "# tb_productos_descripcion.txt es la ultima tabla (∫2024/06/15) que presento con las caracteristicas y categoria de cada producto\n",
    "df_productos_descripcion = pd.read_csv(productos_descripcion, sep='\\t')\n",
    "df_productos_descripcion = df_productos_descripcion[['product_id', 'cat1', 'cat2', 'cat3', 'brand', 'sku_size', 'descripcion']]\n",
    "df_productos_descripcion = df_productos_descripcion.reset_index(drop=True)\n",
    "# Nota: no encuentro duplicados en productos_descripcion. De todas formas armo la sentencia de eliminarlos ya que pueden aparecer\n",
    "#       futuras versiones del archivo\n",
    "# Eliminar los duplicados en la columna 'product_id', manteniendo solo la primera aparición\n",
    "df_productos_descripcion.drop_duplicates(subset='product_id', keep='first', inplace=True)\n",
    "\n",
    "#df_ventas_orig = pd.read_csv(ventas_file_path, sep='\\t')\n",
    "df_ventas_orig = pd.read_csv(ventas_file_path)\n",
    "\n",
    "# Borro columna customer_id \n",
    "#   Esta columna viene del archivo csv que agrupo valores por product_id y periodo. No sabemos si customer_id es un valor totalizado.\n",
    "#   En principio no lo necesito\n",
    "df_ventas = df_ventas_orig.copy()\n",
    "del df_ventas['customer_id']\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# Agregar Periodos faltantes con valor = 0\n",
    "#    LSTM necesita toda la serie temporal en la que los productos fueron vendidos para poder predecir a futuro, incluso\n",
    "#    en meses dde no hubieron ventas. Para estos meses se completa el periodo, product_id y valores a cero para tn (y demas valores tipo numericos)\n",
    "\n",
    "# Primero convertimos la columna 'periodo' en datetime si no está en ese formato\n",
    "df_ventas['periodo'] = pd.to_datetime(df_ventas['periodo'], format='%Y%m')\n",
    "\n",
    "meses = df_ventas.periodo.unique()\n",
    "prod = df_ventas.product_id.unique()\n",
    "\n",
    "all_combinations = pd.MultiIndex.from_product([prod, meses], names=['product_id', 'periodo']).to_frame(index=False)\n",
    "\n",
    "# Unir los datos originales con el DataFrame completo para asegurar que cada producto tenga todos los periodos\n",
    "df_full = pd.merge(all_combinations, df_ventas, on=['product_id', 'periodo'], how='left')\n",
    "\n",
    "# Rellenar los valores faltantes con ceros\n",
    "df_full['tn'] = df_full['tn'].fillna(0)\n",
    "\n",
    "df_ventas = df_full.copy()\n",
    "\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# Agregar la col cant_periodos\n",
    "#    Cant periodos indica cuantos meses hubo ventas de un product_id\n",
    "# Filtrar el DataFrame para excluir los períodos donde 'tn' es cero\n",
    "df_ventas_filtrado = df_ventas[df_ventas['tn'] != 0]\n",
    "\n",
    "# Agrupar por 'product_id' y contar los períodos únicos en el DataFrame filtrado\n",
    "cant_periodos = df_ventas_filtrado.groupby('product_id')['periodo'].nunique()\n",
    "\n",
    "# Agregamos esta información al DataFrame original\n",
    "df_ventas = df_ventas.merge(cant_periodos.rename('cant_periodos'), on='product_id', how='left')\n",
    "\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# Agregamos la descripcion de cada producto (cat1, cat2, cat3, etc)\n",
    "#   Esto podria ser util en caso de querer incorporar nuevas variables al modelo\n",
    "df_ventas = pd.merge(df_ventas, df_productos_descripcion, on=['product_id'], how='left')\n",
    "\n",
    "# Contar la cantidad de NaN en cada columna\n",
    "cantidad_nans_por_columna = df_ventas.isna().sum()\n",
    "print('\\n--------------------------------------')\n",
    "print('Cantidad de NaN x Columna:')\n",
    "print(cantidad_nans_por_columna)\n",
    "\n",
    "# Rellenar los valores faltantes con ceros\n",
    "df_ventas = df_ventas.fillna(0)\n",
    "\n",
    "print('\\n--------------------------------------')\n",
    "print('Completando a 0 los NaN')\n",
    "\n",
    "\n",
    "\n",
    "# Contar la cantidad de NaN en cada columna\n",
    "cantidad_nans_por_columna = df_ventas.isna().sum()\n",
    "print('\\n--------------------------------------')\n",
    "print('Cantidad de NaN x Columna:')\n",
    "print(cantidad_nans_por_columna)\n",
    "\n",
    "\n",
    "\n",
    "print('\\n--------------------------------------\\n')\n",
    "print('Generando archivo final: ../66_Datos/sell-z-780-all-LTSM.csv')\n",
    "\n",
    "# En caso de generar el archivo a csv para uso futuro\n",
    "#df_ventas.to_csv('../66_Datos/sell-z-780-all-LTSM.csv', index=False)\n",
    "df_ventas.round(1).to_excel('../66_Datos/sell-z-780-all-LTSM.xlsx', index=False)\n",
    "\n",
    "print('\\n--------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecutura rapida de Dataset sell-z-780-all-LTSM.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28080 entries, 0 to 28079\n",
      "Data columns (total 13 columns):\n",
      " #   Column                 Non-Null Count  Dtype         \n",
      "---  ------                 --------------  -----         \n",
      " 0   product_id             28080 non-null  int64         \n",
      " 1   periodo                28080 non-null  datetime64[ns]\n",
      " 2   plan_precios_cuidados  22349 non-null  float64       \n",
      " 3   cust_request_qty       22349 non-null  float64       \n",
      " 4   cust_request_tn        22349 non-null  float64       \n",
      " 5   tn                     28080 non-null  float64       \n",
      " 6   cant_periodos          28080 non-null  int64         \n",
      " 7   cat1                   28080 non-null  object        \n",
      " 8   cat2                   28080 non-null  object        \n",
      " 9   cat3                   28080 non-null  object        \n",
      " 10  brand                  28080 non-null  object        \n",
      " 11  sku_size               28080 non-null  int64         \n",
      " 12  descripcion            28080 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(4), int64(3), object(5)\n",
      "memory usage: 2.8+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>periodo</th>\n",
       "      <th>plan_precios_cuidados</th>\n",
       "      <th>cust_request_qty</th>\n",
       "      <th>cust_request_tn</th>\n",
       "      <th>tn</th>\n",
       "      <th>cant_periodos</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>brand</th>\n",
       "      <th>sku_size</th>\n",
       "      <th>descripcion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20001</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>479.0</td>\n",
       "      <td>937.72717</td>\n",
       "      <td>934.77222</td>\n",
       "      <td>36</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>ARIEL</td>\n",
       "      <td>3000</td>\n",
       "      <td>genoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20001</td>\n",
       "      <td>2017-02-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>432.0</td>\n",
       "      <td>833.72187</td>\n",
       "      <td>798.01620</td>\n",
       "      <td>36</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>ARIEL</td>\n",
       "      <td>3000</td>\n",
       "      <td>genoma</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id    periodo  plan_precios_cuidados  cust_request_qty  \\\n",
       "0       20001 2017-01-01                    0.0             479.0   \n",
       "1       20001 2017-02-01                    0.0             432.0   \n",
       "\n",
       "   cust_request_tn         tn  cant_periodos cat1         cat2     cat3  \\\n",
       "0        937.72717  934.77222             36   HC  ROPA LAVADO  Liquido   \n",
       "1        833.72187  798.01620             36   HC  ROPA LAVADO  Liquido   \n",
       "\n",
       "   brand  sku_size descripcion  \n",
       "0  ARIEL      3000      genoma  \n",
       "1  ARIEL      3000      genoma  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ventas_LTSM_path = '../66_Datos/sell-z-780-all-LTSM.csv'\n",
    "df_ventas = pd.read_csv(ventas_LTSM_path)\n",
    "\n",
    "# Convertir la columna 'periodo' a tipo datetime\n",
    "df_ventas['periodo'] = pd.to_datetime(df_ventas['periodo'], format='%Y-%m-%d')\n",
    "\n",
    "# Formatear la fecha según el formato deseado\n",
    "print(df_ventas.info())\n",
    "\n",
    "df_ventas.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# Formula Total Forecast Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-----------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------\n",
      "    >>>>>>>>>>>>       Total Forecast Error: 4.50%     <<<<<<<<<<<<<<<<<<\n",
      "-----------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def calcular_total_forecast_error(actual, forecast):\n",
    "    \"\"\"\n",
    "    Calcula el Total Forecast Error dado un DataFrame con ventas reales y pronosticadas.\n",
    "\n",
    "    Parámetros:\n",
    "    actual (pd.Series): Serie con las ventas reales.\n",
    "    forecast (pd.Series): Serie con las ventas pronosticadas.\n",
    "\n",
    "    Retorna:\n",
    "    float: El Total Forecast Error.\n",
    "    \"\"\"\n",
    "    # Calcular el error absoluto\n",
    "    abs_error = abs(actual - forecast)\n",
    "    \n",
    "    # Calcular el Total Forecast Error\n",
    "    total_forecast_error = abs_error.sum() / actual.sum()\n",
    "    \n",
    "    print(\"\\n\\n-----------------------------------------------------------------------------\")\n",
    "    print(\"-----------------------------------------------------------------------------\")\n",
    "    print(f'    >>>>>>>>>>>>       Total Forecast Error: {total_forecast_error:.2%}     <<<<<<<<<<<<<<<<<<')\n",
    "    print(\"-----------------------------------------------------------------------------\")\n",
    "    print(\"-----------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "    \n",
    "    return total_forecast_error\n",
    "\n",
    "# Ejemplo de uso\n",
    "# Crear un DataFrame de ejemplo\n",
    "data = {\n",
    "    'product_id': [1, 2, 3, 4, 5],\n",
    "    'actual_sales': [100, 150, 200, 250, 300],\n",
    "    'forecast_sales': [110, 145, 190, 260, 310]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Calcular el Total Forecast Error\n",
    "tfe = calcular_total_forecast_error(df['actual_sales'], df['forecast_sales'])\n",
    "#print(\"\\n\\n-----------------------------------------------------------------------------\")\n",
    "#print(\"-----------------------------------------------------------------------------\")\n",
    "#print(f'    >>>>>>>>>>>>       Total Forecast Error: {tfe:.2%}     <<<<<<<<<<<<<<<<<<')\n",
    "#print(\"-----------------------------------------------------------------------------\")\n",
    "#print(\"-----------------------------------------------------------------------------\\n\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{Total Forecast Error} = \\frac{\\sum_{\\text{sku}} |\\text{Actual Sales} - \\text{Forecast Sales}|}{\\sum_{\\text{sku}} \\text{Actual Sales}}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# Funcion nombre_file(sfx)\n",
    "   - Genera el nombre del archivo .csv con prefijo datetime YYYY-MM-DD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../666_Kaggle/Entregas/2024-06-22-1033-MongoAurelio.csv\n",
      "Predicciones ajustadas guardadas en ../666_Kaggle/Entregas/2024-06-22-1033-Sufijo-General_tfe2_0.1235.csv\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------\n",
    "# Funcion nombre_file(sfx)\n",
    "#   - Genera el nombre del archivo .csv con prefijo datetime YYYY-MM-DD\n",
    "from datetime import datetime\n",
    "def nombre_file(sfx):\n",
    "    # Obtener la fecha y hora actual en el formato requerido\n",
    "    current_time = datetime.now().strftime('%Y-%m-%d-%H%M-')\n",
    "\n",
    "    # Path to output dir\n",
    "    output_dir = '../666_Kaggle/Entregas/'    \n",
    "    return(output_dir+current_time+sfx+'.csv')\n",
    "# Indicar el nombre de la prueba\n",
    "suffix_name = 'MongoAurelio' \n",
    "\n",
    "file_to_kaggle = nombre_file(suffix_name)\n",
    "print(file_to_kaggle)\n",
    "\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Esto va al final para escribir el archivo final\n",
    "\n",
    "# Agrego el tfe2 al suffix del archivo\n",
    "#   Calculo del total forecast error\n",
    "#   tfe2 =  calcular_total_forecast_error(all_forecasts['y'], all_forecasts['yhat1'])\n",
    "#    print(f'Total Forecast Error: {tfe2:.2%}')\n",
    "\n",
    "tfe2 = 0.123456789\n",
    "str_tfe2 = \"_tfe2_\" + str(round(tfe2, 4)) \n",
    "\n",
    "# Suffijo general para las dos salidas de archivos\n",
    "#  Solo cambiar este valor\n",
    "\n",
    "suffix_general = 'Sufijo-General'  + str_tfe2\n",
    "\n",
    "# Usar la función nombre_file para asignar el nombre del archivo de salida para kaggle\n",
    "suffix_to_kaagle_name = suffix_general\n",
    "file_to_kaggle = nombre_file(suffix_to_kaagle_name)\n",
    "# Colocar el nombre del df apropiado\n",
    "#df_aGuardarEnDisco.to_csv(file_to_kaggle, index=False)\n",
    "\n",
    "#all_forecasts.to_csv(file_to_kaggle+'all', index=False)\n",
    "print(f'Predicciones ajustadas guardadas en {file_to_kaggle}')\n",
    "\n",
    "# Fin\n",
    "# ------------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../666_Kaggle/Entregas/2024-06-22-1033-MongoAurelio_tfe2_0.1235.csv\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------\n",
    "# Funcion nombre_file(sfx)\n",
    "#   - Genera el nombre del archivo .csv con prefijo datetime YYYY-MM-DD\n",
    "from datetime import datetime\n",
    "def nombre_file(sfx):\n",
    "    # Obtener la fecha y hora actual en el formato requerido\n",
    "    current_time = datetime.now().strftime('%Y-%m-%d-%H%M-')\n",
    "\n",
    "    # Path to output dir\n",
    "    output_dir = '../666_Kaggle/Entregas/'    \n",
    "    return(output_dir+current_time+sfx+'.csv')\n",
    "\n",
    "# Indicar el nombre de la prueba\n",
    "\n",
    "\n",
    "# Agrego el tfe2 al suffix del archivo\n",
    "#   Calculo del total forecast error\n",
    "#   tfe2 =  calcular_total_forecast_error(all_forecasts['y'], all_forecasts['yhat1'])\n",
    "#    print(f'Total Forecast Error: {tfe2:.2%}')\n",
    "\n",
    "tfe2 = 0.123456789\n",
    "str_tfe2 = \"_tfe2_\" + str(round(tfe2, 4)) \n",
    "\n",
    "suffix_name = 'MongoAurelio' + str_tfe2\n",
    "file_to_kaggle = nombre_file(suffix_name)\n",
    "print(file_to_kaggle)\n",
    "# --------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "#  Sell-in - Datos de Ventas \n",
    "\n",
    "### sell-in.txt\n",
    "\n",
    "El archivo de ventas contiene todos los datos de ventas facilitados por el docente. Es la tabla punto de partida para las ventas. \n",
    "\n",
    "Contiene las siguientes columnas:\n",
    "\n",
    "1. **periodo**: Representa el período de tiempo en formato `yyyymm` (año y mes).\n",
    "    - Minimum\t2017-01-01 00:00:00\n",
    "    - Maximum\t2019-12-01 00:00:00\n",
    "2. **customer_id**: Identificación única del cliente.\n",
    "3. **product_id**: Identificación única del producto.\n",
    "4. **plan_precios_cuidados**: Indicador binario (0 o 1) que señala si el producto está incluido en el plan de precios cuidados.\n",
    "5. **cust_request_qty**: Cantidad de producto solicitada por el cliente.\n",
    "6. **cust_request_tn**: Peso en toneladas solicitado por el cliente.\n",
    "7. **tn**: Peso en toneladas del producto vendido.\n",
    "\n",
    "Estas columnas proporcionan información detallada sobre las ventas realizadas en distintos períodos, especificando el cliente, el producto, y las cantidades en unidades y en peso.\n",
    "\n",
    "\n",
    "### sell-z-780-all-prodId.csv\n",
    "sell-z-780-all-prodId.csv es una vista de la tabla sell-in.txt con solamente los movimientos de los 780 productos que hay que predeicr (productos_a_predecir.txt).\n",
    "Las ventas de productos por peridos no estan agregadas. Esto es, existen para un mismo producto en un mismo perodo multiples entradas.  \n",
    "  EJ:\n",
    "\n",
    "| Periodo | product_id | tn   |\n",
    "|---------|------------|------|\n",
    "| 2018-01 | 20001      | 1360 |\n",
    "| 2018-01 | 20001      | 160  |\n",
    "| 2018-01 | 20055      | 3360 |\n",
    "\n",
    "### sell-z-780-groupBy-Period-ProdId.csv\n",
    "sell-z-780-groupBy-Period-ProdId.csv contiene los mismos datos que sell-z-780-all-prodId.csv pero agrupados por 'periodo' y 'product_id'. Es decir, para un producto que tuvo multiples ventas en un periodo tengo agrupadas las ventas para ese periodo.\n",
    "\n",
    "Ej. \n",
    "| Periodo | product_id | tn   |\n",
    "|---------|------------|------|\n",
    "| 2018-01 | 20001      | 1520 |\n",
    "| 2018-01 | 20055      | 3360 |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w1/fwmwl18j7yvfc0766bv7m8_r0000gn/T/ipykernel_2707/356992897.py:32: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  sell_780_groupBy_Periodo_ProdId = sell_780_all.groupby(['periodo', 'product_id'], as_index=False).sum()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar los datos de ventas y productos a predecir\n",
    "ventas_file_path = '../66_Datos/sell-in.txt'\n",
    "productos_file_path = '../66_Datos/productos_a_predecir.txt'\n",
    "productos_descripcion = '../66_Datos/tb_productos_descripcion.txt'\n",
    "\n",
    "df_productos_descripcion = pd.read_csv(productos_descripcion, sep='\\t')\n",
    "df_productos_descripcion = df_productos_descripcion[['product_id', 'cat1', 'cat2', 'cat3', 'brand', 'sku_size', 'descripcion']]\n",
    "df_productos_descripcion = df_productos_descripcion.reset_index(drop=True)\n",
    "# Nota: no encuentro duplicados en productos_descripcion. De todas formas armo la sentencia de eliminarlos ya que pueden aparecer\n",
    "#       futuras versiones del archivo\n",
    "# Eliminar los duplicados en la columna 'product_id', manteniendo solo la primera aparición\n",
    "df_productos_descripcion.drop_duplicates(subset='product_id', keep='first', inplace=True)\n",
    "\n",
    "df_ventas_orig = pd.read_csv(ventas_file_path, sep='\\t')\n",
    "\n",
    "df_ventas = pd.merge(df_ventas_orig, df_productos_descripcion, on=['product_id'], how='left')\n",
    "\n",
    "\n",
    "df_productos = pd.read_csv(productos_file_path, sep='\\t')\n",
    "\n",
    "\n",
    "# Filtrar las ventas para que solo incluya los productos a predecir\n",
    "productos_a_predecir = df_productos['product_id'].unique()\n",
    "sell_780_all = df_ventas[df_ventas['product_id'].isin(productos_a_predecir)]\n",
    "\n",
    "\n",
    "sell_780_groupBy_Periodo_ProdId = sell_780_all.groupby(['periodo', 'product_id'], as_index=False).sum()\n",
    "\n",
    "# Opcional: Guardar el DataFrame filtrado en un archivo CSV\n",
    "#df['ds'] = pd.to_datetime(df['periodo'], format='%Y%m')\n",
    "df_ventas_toCsv = df_ventas\n",
    "df_ventas_toCsv['periodo'] = pd.to_datetime(df_ventas_toCsv['periodo'], format='%Y%m')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar CSVs \n",
    "df_ventas_toCsv.to_csv('../66_Datos/sell-in.csv', index=False)\n",
    "sell_780_all.to_csv('../66_Datos/sell-z-780-all-prodId.csv', index=False)\n",
    "sell_780_groupBy_Periodo_ProdId.to_csv('../66_Datos/sell-z-780-groupBy-Period-ProdId.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_productos_descripcion = df_productos_descripcion[['product_id', 'cat1', 'cat2', 'cat3', 'brand', 'sku_size', 'descripcion']]\n",
    "df_productos_descripcion = df_productos_descripcion.reset_index(drop=True)\n",
    "\n",
    "# Nota: no encuentro duplicados en productos_descripcion. De todas formas armo la sentencia de eliminarlos ya que pueden aparecer\n",
    "#       futuras versiones del archivo\n",
    "# Eliminar los duplicados en la columna 'product_id', manteniendo solo la primera aparición\n",
    "df_productos_descripcion.drop_duplicates(subset='product_id', keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.merge(df_ventas, df_productos_descripcion, on=['product_id'], how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV de las ventas de todos los 780 con el campo periodo convertido a datetime\n",
    "#   Este archivo lo uso en Orange y nec que periodo tenga formato fecha\n",
    "sell_780_all_toDatetime_toCsv = sell_780_all.copy()\n",
    "sell_780_all_toDatetime_toCsv['periodo'] = pd.to_datetime(sell_780_all_toDatetime_toCsv['periodo'], format='%Y%m')\n",
    "sell_780_all_toDatetime_toCsv.to_csv('../66_Datos/sell-z-780-all-prodId-toDatetime.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>periodo</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>plan_precios_cuidados</th>\n",
       "      <th>cust_request_qty</th>\n",
       "      <th>cust_request_tn</th>\n",
       "      <th>tn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44019</th>\n",
       "      <td>201701</td>\n",
       "      <td>10001</td>\n",
       "      <td>20001</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>99.43861</td>\n",
       "      <td>99.43861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44020</th>\n",
       "      <td>201701</td>\n",
       "      <td>10063</td>\n",
       "      <td>20001</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.12312</td>\n",
       "      <td>0.12312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44021</th>\n",
       "      <td>201701</td>\n",
       "      <td>10080</td>\n",
       "      <td>20001</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24625</td>\n",
       "      <td>0.24625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44022</th>\n",
       "      <td>201701</td>\n",
       "      <td>10094</td>\n",
       "      <td>20001</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.23123</td>\n",
       "      <td>1.23123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44023</th>\n",
       "      <td>201701</td>\n",
       "      <td>10184</td>\n",
       "      <td>20001</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.06716</td>\n",
       "      <td>0.06716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       periodo  customer_id  product_id  plan_precios_cuidados  \\\n",
       "44019   201701        10001       20001                      0   \n",
       "44020   201701        10063       20001                      0   \n",
       "44021   201701        10080       20001                      0   \n",
       "44022   201701        10094       20001                      0   \n",
       "44023   201701        10184       20001                      0   \n",
       "\n",
       "       cust_request_qty  cust_request_tn        tn  \n",
       "44019                11         99.43861  99.43861  \n",
       "44020                 1          0.12312   0.12312  \n",
       "44021                 1          0.24625   0.24625  \n",
       "44022                 1          1.23123   1.23123  \n",
       "44023                 1          0.06716   0.06716  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sell_780_all.loc[(sell_780_all['product_id'] == 20001) & (sell_780_all['periodo'] == 201701)].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sell-z-39-all-prodId + sell-z-39-groupBy-Period-ProdId\n",
    "\n",
    "Version con 39 productos que representan el 5% para pruebas rapidas\n",
    "\n",
    "\n",
    "\n",
    "sell-z-39-groupBy-Period-ProdId.csv es una version reducida de los datos de ventas (con el 5% de productos a predecir= y contiene los datos de ventas agrupados por 'periodo' y 'product_id'. Es decir, para un producto que tuvo multiples ventas en un periodo tengo agrupadas las ventas para ese periodo.\n",
    "\n",
    "Ej. \n",
    "| Periodo | product_id | tn   |\n",
    "|---------|------------|------|\n",
    "| 201801 | 20001      | 1520 |\n",
    "| 201801 | 20055      | 3360 |\n",
    "| 201802 | 20011      | 1320 |\n",
    "| 201802 | 20021      | 1220 |\n",
    "| 201802 | 20031      | 120 |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar los datos de ventas y productos a predecir\n",
    "ventas_file_path = '../66_Datos/sell-in.txt'\n",
    "productos_file_path = '../66_Datos/productos_a_predecir-39.txt'\n",
    "\n",
    "df_ventas = pd.read_csv(ventas_file_path, sep='\\t')\n",
    "df_productos = pd.read_csv(productos_file_path, sep='\\t')\n",
    "\n",
    "# Filtrar las ventas para que solo incluya los productos a predecir\n",
    "productos_a_predecir = df_productos['product_id'].unique()\n",
    "sell_39_all = df_ventas[df_ventas['product_id'].isin(productos_a_predecir)]\n",
    "\n",
    "\n",
    "sell_39_groupBy_Periodo_ProdId = sell_39_all.groupby(['periodo', 'product_id'], as_index=False).sum()\n",
    "\n",
    "# Opcional: Guardar el DataFrame filtrado en un archivo CSV\n",
    "sell_39_all.to_csv('../66_Datos/sell-z-39-all-prodId.csv', index=False)\n",
    "sell_39_groupBy_Periodo_ProdId.to_csv('../66_Datos/sell-z-39-groupBy-Period-ProdId.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Misc Temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range(2021, 2030)\n"
     ]
    }
   ],
   "source": [
    "print(range(2021, 2030))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ds   y\n",
      "0  2021-01-01 NaN\n",
      "1  2022-01-01 NaN\n",
      "2  2023-01-01 NaN\n",
      "3  2024-01-01 NaN\n",
      "4  2025-01-01 NaN\n",
      "5  2026-01-01 NaN\n",
      "6  2027-01-01 NaN\n",
      "7  2028-01-01 NaN\n",
      "8  2029-01-01 NaN\n",
      "9  2030-01-01 NaN\n",
      "10 2031-01-01 NaN\n",
      "11 2032-01-01 NaN\n",
      "12 2033-01-01 NaN\n",
      "13 2034-01-01 NaN\n",
      "14 2035-01-01 NaN\n",
      "15 2036-01-01 NaN\n",
      "16 2037-01-01 NaN\n",
      "17 2038-01-01 NaN\n",
      "18 2039-01-01 NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Crear un DataFrame con fechas desde 2021 hasta 2039\n",
    "f2 = pd.DataFrame({\n",
    "    'ds': pd.to_datetime([str(x) for x in range(2021, 2040)], format='%Y'),\n",
    "    'y': np.nan\n",
    "})\n",
    "\n",
    "print(f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2038-01-01 00:00:00')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 2021 a 2090\n",
    "futuro = pd.DataFrame({\n",
    "    'ds': pd.to_datetime([x for x in range(2021, 2025)], format='%Y'),\n",
    "    'y': np.nan\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ds   y\n",
       "0 2021-01-01 NaN\n",
       "1 2022-01-01 NaN\n",
       "2 2023-01-01 NaN\n",
       "3 2024-01-01 NaN"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "futuro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2021-01-01', '2022-01-01', '2023-01-01', '2024-01-01'], dtype='datetime64[ns]', freq=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime([x for x in range(2021, 2025)], format='%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>periodo</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>plan_precios_cuidados</th>\n",
       "      <th>cust_request_qty</th>\n",
       "      <th>cust_request_tn</th>\n",
       "      <th>tn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201701</td>\n",
       "      <td>10234</td>\n",
       "      <td>20524</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.05300</td>\n",
       "      <td>0.05300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201701</td>\n",
       "      <td>10032</td>\n",
       "      <td>20524</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.13628</td>\n",
       "      <td>0.13628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201701</td>\n",
       "      <td>10217</td>\n",
       "      <td>20524</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03028</td>\n",
       "      <td>0.03028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201701</td>\n",
       "      <td>10125</td>\n",
       "      <td>20524</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.02271</td>\n",
       "      <td>0.02271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201701</td>\n",
       "      <td>10012</td>\n",
       "      <td>20524</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1.54452</td>\n",
       "      <td>1.54452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2945813</th>\n",
       "      <td>201912</td>\n",
       "      <td>10105</td>\n",
       "      <td>20853</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.02230</td>\n",
       "      <td>0.02230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2945814</th>\n",
       "      <td>201912</td>\n",
       "      <td>10092</td>\n",
       "      <td>20853</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00669</td>\n",
       "      <td>0.00669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2945815</th>\n",
       "      <td>201912</td>\n",
       "      <td>10006</td>\n",
       "      <td>20853</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.02898</td>\n",
       "      <td>0.02898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2945816</th>\n",
       "      <td>201912</td>\n",
       "      <td>10018</td>\n",
       "      <td>20853</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.01561</td>\n",
       "      <td>0.01561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2945817</th>\n",
       "      <td>201912</td>\n",
       "      <td>10020</td>\n",
       "      <td>20853</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01561</td>\n",
       "      <td>0.01561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2945818 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         periodo  customer_id  product_id  plan_precios_cuidados  \\\n",
       "0         201701        10234       20524                      0   \n",
       "1         201701        10032       20524                      0   \n",
       "2         201701        10217       20524                      0   \n",
       "3         201701        10125       20524                      0   \n",
       "4         201701        10012       20524                      0   \n",
       "...          ...          ...         ...                    ...   \n",
       "2945813   201912        10105       20853                      0   \n",
       "2945814   201912        10092       20853                      0   \n",
       "2945815   201912        10006       20853                      0   \n",
       "2945816   201912        10018       20853                      0   \n",
       "2945817   201912        10020       20853                      0   \n",
       "\n",
       "         cust_request_qty  cust_request_tn       tn  \n",
       "0                       2          0.05300  0.05300  \n",
       "1                       1          0.13628  0.13628  \n",
       "2                       1          0.03028  0.03028  \n",
       "3                       1          0.02271  0.02271  \n",
       "4                      11          1.54452  1.54452  \n",
       "...                   ...              ...      ...  \n",
       "2945813                 1          0.02230  0.02230  \n",
       "2945814                 1          0.00669  0.00669  \n",
       "2945815                 7          0.02898  0.02898  \n",
       "2945816                 4          0.01561  0.01561  \n",
       "2945817                 2          0.01561  0.01561  \n",
       "\n",
       "[2945818 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ventas To Postgres\n",
    "\n",
    "Generar archivo sell-in-to-Postgres con:\n",
    " 1. Todas las ventas registradas en sell-in.txt\n",
    " 2. Agregar columna `en780` indicando con 1 aquellas filas que contienen product_id perteneciente al listado de 780 productos a predecir (productos_a_predecir.csv)\n",
    " 3. Merge de las ventas en sell-in.txt con la descripcion de productos en tb_productos_descripcion.txt (join by product_id)\n",
    " 4. Agregar columna `cant_periodos`, y en cada celda agregar la cantidad de meses que tuvo ventas el product_id de la fila. Por ejemplo si el product_id 20001 tuvo ventas durante los 36 meses, en la columna cant_periodos debe ir 36. \n",
    " 5. Exportar a csv  sell-in-all-to-postgres.csv\n",
    "\n",
    "\n",
    "Como identificar productos vendidos durante los 36 meses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar los datos de ventas y productos a predecir\n",
    "ventas_file_path = '../66_Datos/sell-in.txt'\n",
    "productos_file_path = '../66_Datos/productos_a_predecir.txt'\n",
    "productos_descripcion = '../66_Datos/tb_productos_descripcion.txt'\n",
    "\n",
    "\n",
    "# tb_productos_descripcion.txt es la ultima tabla (2024/06/15) que presento con las caracteristicas y categoria de cada producto\n",
    "df_productos_descripcion = pd.read_csv(productos_descripcion, sep='\\t')\n",
    "df_productos_descripcion = df_productos_descripcion[['product_id', 'cat1', 'cat2', 'cat3', 'brand', 'sku_size', 'descripcion']]\n",
    "df_productos_descripcion = df_productos_descripcion.reset_index(drop=True)\n",
    "# Nota: no encuentro duplicados en productos_descripcion. De todas formas armo la sentencia de eliminarlos ya que pueden aparecer\n",
    "#       futuras versiones del archivo\n",
    "# Eliminar los duplicados en la columna 'product_id', manteniendo solo la primera aparición\n",
    "df_productos_descripcion.drop_duplicates(subset='product_id', keep='first', inplace=True)\n",
    "\n",
    "df_ventas_orig = pd.read_csv(ventas_file_path, sep='\\t')\n",
    "\n",
    "df_ventas = pd.merge(df_ventas_orig, df_productos_descripcion, on=['product_id'], how='left')\n",
    "\n",
    "# Cargamos los productos a predecir (780)\n",
    "df_productos = pd.read_csv(productos_file_path, sep='\\t')\n",
    "\n",
    "\n",
    "# Filtrar las ventas para que solo incluya los productos a predecir. Va .unique() \n",
    "productos_a_predecir = df_productos['product_id'].unique()\n",
    "\n",
    "# Agregar la columna \"en780\" a df_ventas\n",
    "df_ventas['en780'] = df_ventas['product_id'].apply(lambda x: 1 if x in productos_a_predecir else 0)\n",
    "\n",
    "# Agregar columna `cant_periodos`\n",
    "# Primero convertimos la columna 'periodo' en datetime si no está en ese formato\n",
    "df_ventas['periodo'] = pd.to_datetime(df_ventas['periodo'], format='%Y%m')\n",
    "\n",
    "# Agrupamos por 'product_id' y contamos los periodos únicos\n",
    "cant_periodos = df_ventas.groupby('product_id')['periodo'].nunique()\n",
    "\n",
    "# Agregamos esta información al DataFrame original\n",
    "df_ventas = df_ventas.merge(cant_periodos.rename('cant_periodos'), on='product_id', how='left')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Valores nulos df_productos_descripcion y df_ventas\n",
    "\n",
    "Resulta que en la tabla productos_descripcion.txt hay un listado de 45 productos vendidos durante los 36 peridos que no figuran.\n",
    " - Voy a completar esos nulos tanto en la tabla que llevo a postgres sell_all (sell-in-all-to-postgres.csv) como productos2 (tb_productos_descripcion_ac.csv)\n",
    " - Estoy completando las variables cat1, cat2, cat3, brand y descripción con el string 'sinCatego'\n",
    " - Estoy completando la variable sku_size con 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores nulos en cat1: 7448\n",
      "Valores nulos en cat2: 7448\n",
      "Valores nulos en cat3: 7448\n",
      "Valores nulos en brand: 7448\n",
      "Valores nulos en sku_size: 7448\n",
      "Valores nulos en descripcion: 7448\n",
      "Valores nulos en cat1: 0\n",
      "Valores nulos en cat2: 0\n",
      "Valores nulos en cat3: 0\n",
      "Valores nulos en brand: 0\n",
      "Valores nulos en sku_size: 0\n",
      "Valores nulos en descripcion: 0\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "Product IDs que faltan en df_productos_descripcion:\n",
      "{21249, 21253, 21125, 21268, 21270, 21272, 21273, 21274, 21275, 21277, 21278, 21279, 21281, 21283, 21284, 21285, 21286, 21288, 21289, 21290, 21291, 21292, 21165, 21293, 21295, 21296, 21297, 21298, 21299, 21169, 20918, 21178, 20808, 21066, 21199, 21217, 21223, 21225, 21098, 21228, 21230, 20848, 21238, 21240, 21241}\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "      product_id       cat1       cat2         cat3      brand  sku_size  \\\n",
      "0          20609      FOODS   ADEREZOS  Aji Picante     NATURA       240   \n",
      "1          20266      FOODS   ADEREZOS     Barbacoa     NATURA       250   \n",
      "2          20325      FOODS   ADEREZOS     Barbacoa     NATURA       400   \n",
      "3          20503      FOODS   ADEREZOS     Barbacoa     NATURA       500   \n",
      "4          20797      FOODS   ADEREZOS  Chimichurri     NATURA       350   \n",
      "...          ...        ...        ...          ...        ...       ...   \n",
      "1291       21230  sinCatego  sinCatego    sinCatego  sinCatego         0   \n",
      "1292       20848  sinCatego  sinCatego    sinCatego  sinCatego         0   \n",
      "1293       21238  sinCatego  sinCatego    sinCatego  sinCatego         0   \n",
      "1294       21240  sinCatego  sinCatego    sinCatego  sinCatego         0   \n",
      "1295       21241  sinCatego  sinCatego    sinCatego  sinCatego         0   \n",
      "\n",
      "            descripcion  \n",
      "0     Salsa Aji Picante  \n",
      "1        Salsa Barbacoa  \n",
      "2        Salsa Barbacoa  \n",
      "3        Salsa Barbacoa  \n",
      "4           Chimichurri  \n",
      "...                 ...  \n",
      "1291          sinCatego  \n",
      "1292          sinCatego  \n",
      "1293          sinCatego  \n",
      "1294          sinCatego  \n",
      "1295          sinCatego  \n",
      "\n",
      "[1296 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Verificar si hay valores nulos en cat1, cat2, cat3, brand, sku_size, descripcion\n",
    "nulos_cat1 = df_ventas['cat1'].isnull().sum()\n",
    "nulos_cat2 = df_ventas['cat2'].isnull().sum()\n",
    "nulos_cat3 = df_ventas['cat3'].isnull().sum()\n",
    "nulos_brand = df_ventas['brand'].isnull().sum()\n",
    "nulos_sku_size = df_ventas['sku_size'].isnull().sum()\n",
    "nulos_descripcion = df_ventas['descripcion'].isnull().sum()\n",
    "\n",
    "print(f'Valores nulos en cat1: {nulos_cat1}')\n",
    "print(f'Valores nulos en cat2: {nulos_cat2}')\n",
    "print(f'Valores nulos en cat3: {nulos_cat3}')\n",
    "print(f'Valores nulos en brand: {nulos_brand}')\n",
    "print(f'Valores nulos en sku_size: {nulos_sku_size}')\n",
    "print(f'Valores nulos en descripcion: {nulos_descripcion}')\n",
    "\n",
    "\n",
    "# Reemplazar valores nulos en columnas tipo object con \"sinCatego\"\n",
    "cols_object = ['cat1', 'cat2', 'cat3', 'brand', 'descripcion']\n",
    "for col in cols_object:\n",
    "    df_ventas[col].fillna('sinCatego', inplace=True)\n",
    "\n",
    "# Reemplazar valores nulos en columnas numéricas con 0\n",
    "cols_numeric = ['sku_size']\n",
    "for col in cols_numeric:\n",
    "    df_ventas[col].fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "# Verificar si hay valores nulos en cat1, cat2, cat3, brand, sku_size, descripcion\n",
    "nulos_cat1 = df_ventas['cat1'].isnull().sum()\n",
    "nulos_cat2 = df_ventas['cat2'].isnull().sum()\n",
    "nulos_cat3 = df_ventas['cat3'].isnull().sum()\n",
    "nulos_brand = df_ventas['brand'].isnull().sum()\n",
    "nulos_sku_size = df_ventas['sku_size'].isnull().sum()\n",
    "nulos_descripcion = df_ventas['descripcion'].isnull().sum()\n",
    "\n",
    "print(f'Valores nulos en cat1: {nulos_cat1}')\n",
    "print(f'Valores nulos en cat2: {nulos_cat2}')\n",
    "print(f'Valores nulos en cat3: {nulos_cat3}')\n",
    "print(f'Valores nulos en brand: {nulos_brand}')\n",
    "print(f'Valores nulos en sku_size: {nulos_sku_size}')\n",
    "print(f'Valores nulos en descripcion: {nulos_descripcion}')\n",
    "\n",
    "\n",
    "print('--------------------------------------')\n",
    "print('--------------------------------------')\n",
    "\n",
    "\n",
    "\n",
    "# Filtrar los productos en df_ventas donde cat1 es 'sinCatego'\n",
    "productos_sin_categoria = df_ventas[df_ventas['cat1'] == 'sinCatego']['product_id'].unique()\n",
    "\n",
    "# Encontrar los product_id que faltan en df_productos_descripcion\n",
    "productos_descripcion_ids = df_productos_descripcion['product_id'].unique()\n",
    "productos_faltantes = set(productos_sin_categoria) - set(productos_descripcion_ids)\n",
    "\n",
    "# Mostrar los product_id que faltan en df_productos_descripcion\n",
    "print('Product IDs que faltan en df_productos_descripcion:')\n",
    "print(productos_faltantes)\n",
    "\n",
    "\n",
    "print('--------------------------------------')\n",
    "print('--------------------------------------')\n",
    "\n",
    "\n",
    "# Crear un DataFrame con los productos faltantes\n",
    "productos_faltantes_df = pd.DataFrame({\n",
    "    'product_id': list(productos_faltantes),\n",
    "    'cat1': 'sinCatego',\n",
    "    'cat2': 'sinCatego',\n",
    "    'cat3': 'sinCatego',\n",
    "    'brand': 'sinCatego',\n",
    "    'sku_size': 0,\n",
    "    'descripcion': 'sinCatego'\n",
    "})\n",
    "\n",
    "# Concatenar el DataFrame de productos faltantes con df_productos_descripcion\n",
    "df_productos_descripcion_completo = pd.concat([df_productos_descripcion, productos_faltantes_df], ignore_index=True)\n",
    "\n",
    "# Verificar el resultado\n",
    "print(df_productos_descripcion_completo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opcional: Guardar el DataFrame filtrado en un archivo CSV\n",
    "#df['ds'] = pd.to_datetime(df['periodo'], format='%Y%m')\n",
    "df_ventas_toCsv = df_ventas\n",
    "#df_ventas_toCsv['periodo'] = pd.to_datetime(df_ventas_toCsv['periodo'], format='%Y%m')\n",
    "\n",
    "# Genero el csv para crear en pg z_l3.sell_all\n",
    "df_ventas_toCsv.to_csv('../66_Datos/sell-in-all-to-postgres.csv', index=False)\n",
    "\n",
    "\n",
    "# Genero el csv para crear en pg z_l3.productos2\n",
    "df_productos_descripcion_completo.to_csv('../66_Datos/tb_productos_descripcion_ac.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>periodo</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>plan_precios_cuidados</th>\n",
       "      <th>cust_request_qty</th>\n",
       "      <th>cust_request_tn</th>\n",
       "      <th>tn</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>brand</th>\n",
       "      <th>sku_size</th>\n",
       "      <th>descripcion</th>\n",
       "      <th>en780</th>\n",
       "      <th>cant_periodos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76331</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>10007</td>\n",
       "      <td>20808</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00197</td>\n",
       "      <td>0.00197</td>\n",
       "      <td>sinCatego</td>\n",
       "      <td>sinCatego</td>\n",
       "      <td>sinCatego</td>\n",
       "      <td>sinCatego</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sinCatego</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76332</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>10135</td>\n",
       "      <td>20808</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00197</td>\n",
       "      <td>0.00197</td>\n",
       "      <td>sinCatego</td>\n",
       "      <td>sinCatego</td>\n",
       "      <td>sinCatego</td>\n",
       "      <td>sinCatego</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sinCatego</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76333</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>10171</td>\n",
       "      <td>20808</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01179</td>\n",
       "      <td>0.01179</td>\n",
       "      <td>sinCatego</td>\n",
       "      <td>sinCatego</td>\n",
       "      <td>sinCatego</td>\n",
       "      <td>sinCatego</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sinCatego</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76334</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>10252</td>\n",
       "      <td>20808</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.06683</td>\n",
       "      <td>0.06683</td>\n",
       "      <td>sinCatego</td>\n",
       "      <td>sinCatego</td>\n",
       "      <td>sinCatego</td>\n",
       "      <td>sinCatego</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sinCatego</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76335</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>10040</td>\n",
       "      <td>20808</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.62310</td>\n",
       "      <td>0.62310</td>\n",
       "      <td>sinCatego</td>\n",
       "      <td>sinCatego</td>\n",
       "      <td>sinCatego</td>\n",
       "      <td>sinCatego</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sinCatego</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         periodo  customer_id  product_id  plan_precios_cuidados  \\\n",
       "76331 2017-01-01        10007       20808                      0   \n",
       "76332 2017-01-01        10135       20808                      0   \n",
       "76333 2017-01-01        10171       20808                      0   \n",
       "76334 2017-01-01        10252       20808                      0   \n",
       "76335 2017-01-01        10040       20808                      0   \n",
       "\n",
       "       cust_request_qty  cust_request_tn       tn       cat1       cat2  \\\n",
       "76331                 1          0.00197  0.00197  sinCatego  sinCatego   \n",
       "76332                 1          0.00197  0.00197  sinCatego  sinCatego   \n",
       "76333                 1          0.01179  0.01179  sinCatego  sinCatego   \n",
       "76334                 1          0.06683  0.06683  sinCatego  sinCatego   \n",
       "76335                 4          0.62310  0.62310  sinCatego  sinCatego   \n",
       "\n",
       "            cat3      brand  sku_size descripcion  en780  cant_periodos  \n",
       "76331  sinCatego  sinCatego       0.0   sinCatego      0             27  \n",
       "76332  sinCatego  sinCatego       0.0   sinCatego      0             27  \n",
       "76333  sinCatego  sinCatego       0.0   sinCatego      0             27  \n",
       "76334  sinCatego  sinCatego       0.0   sinCatego      0             27  \n",
       "76335  sinCatego  sinCatego       0.0   sinCatego      0             27  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ventas.loc[df_ventas.product_id == 20808].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
