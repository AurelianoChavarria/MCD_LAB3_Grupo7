{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dd47bf1-b760-4303-96a7-42a69a094ef6",
   "metadata": {},
   "source": [
    "<table style=\"text-align: left; width: 100%;\" border=\"0\"\n",
    " cellpadding=\"0\" cellspacing=\"0\">\n",
    "\n",
    "  <tbody>\n",
    "    <tr align=\"center\" style=\"height: 1px; background-color: rgb(0, 0, 0);\">\n",
    "      <td><big><big><big><big>Grupo-7</big></big></big></td>\n",
    "      <td><big><big><big><big><span style=\"font-family: Calibri; color: white; font-weight: bold;\">Laboratorio III</span></big></big></big></big></td>\n",
    "      <td><img src=\"https://i.imgur.com/YOQky86.png\" title=\"source: imgur.com\" style=\"width: 250px; height: auto;\" /></td>\n",
    "    </tr>\n",
    "    <tr align=\"center\">\n",
    "      <td colspan=\"3\" rowspan=\"1\"\n",
    " style=\"height: 1px; background-color: rgb(68, 68, 100);\"></td>\n",
    "    </tr>\n",
    "    <tr align=\"center\">\n",
    "      <td colspan=\"3\" rowspan=\"1\"><big><big><big><big><span\n",
    " style=\"font-family: Calibri;\">Modelo LSTM</span></big></big></big></big><br>\n",
    "      </td></tr>\n",
    "    <tr align=\"center\">       \n",
    "      <td colspan=\"3\" rowspan=\"1\" style=\"height: 1px; background-color: rgb(68, 68, 100);\"></td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "\n",
    "<span style=\"font-family: Calibri; font-weight: bold; \">Autores:</span>\n",
    "<br style=\"font-family: Calibri; font-style: italic;\">\n",
    "<span style=\"font-family: Calibri; font-style: italic;\">\n",
    "- Aureliano Chavarria\n",
    "- Gastón Larregui\n",
    "- Patricia Nuñez\n",
    "</span>\n",
    "\n",
    "\n",
    "\n",
    "<div class=\"footer\">&copy; 2024</div>\n",
    "jupyter nbconvert --to script xxx.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9221db22-b474-4428-ba4c-a3b53c8697da",
   "metadata": {},
   "source": [
    "# Optimización y Ajuste de Pesos en Redes Neuronales. \n",
    "\n",
    "Dentro de este tema, puedes encontrar subtemas específicos relacionados con LSTM, como:\n",
    "\n",
    "1. **Ajuste de Pesos en LSTM**\n",
    "2. **Funciones de Pérdida y Optimización en Redes Neuronales**\n",
    "3. **Importancia de las Características en Modelos Recurrentes**\n",
    "4. **Uso de Pesos en Puertas de LSTM**\n",
    "5. **Propagación hacia Atrás (Backpropagation) a través del Tiempo (BPTT)**\n",
    "\n",
    "Estos subtemas abarcan cómo los pesos se ajustan y optimizan durante el entrenamiento de redes neuronales, especialmente en el contexto de LSTM y otros modelos recurrentes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d267089a-1500-438f-b48d-56c5871dce40",
   "metadata": {},
   "source": [
    "# Label Encoding\n",
    "\n",
    "One-Hot Encoding y Label Encoding son dos técnicas comunes para transformar variables categóricas en un formato numérico que los modelos de aprendizaje automático pueden utilizar. Vamos a explorar en qué consisten cada una y por qué se podría recomendar una sobre la otra en el contexto de un modelo LSTM.\n",
    "\n",
    "\n",
    "Label Encoding asigna un número entero único a cada categoría.\n",
    "\n",
    "Ventajas:\n",
    "\n",
    "- Eficiencia: No aumenta el número de columnas. Solo convierte la categoría en un número.\n",
    "- Simplicidad: Fácil de implementar y consume menos memoria.\n",
    "\n",
    "Desventajas:\n",
    "\n",
    "- Suposición de orden: Puede introducir un orden implícito en las categorías, lo que no siempre es deseable o correcto. Los modelos pueden interpretar incorrectamente que una categoría tiene más peso o importancia que otra.\n",
    "\n",
    "¿Por qué Label Encoding podría ser mejor para tu modelo LSTM?\n",
    "\n",
    "1.\tEficiencia: En un modelo LSTM, que maneja secuencias de datos, mantener la dimensionalidad baja es importante para la eficiencia del modelo. One-Hot Encoding puede incrementar significativamente la dimensionalidad si hay muchas categorías, mientras que Label Encoding mantiene una sola columna.\n",
    "2.\tManejo de Secuencias: Label Encoding es más eficiente cuando se trata de secuencias, ya que no aumenta la cantidad de datos a procesar en cada paso de la secuencia. Esto puede hacer que el modelo sea más rápido y menos propenso a problemas de memoria."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd952fb-18f3-40df-8a41-f48b581bff83",
   "metadata": {},
   "source": [
    "Cómo Funciona con estos Datos\n",
    "\n",
    "Con 36 meses de datos y seq_length de 12, se crearán secuencias de la siguiente manera:\n",
    "\n",
    "\t1.Primera Secuencia:\n",
    "    \t•Datos: Meses 1 a 12\n",
    "    \t•Etiqueta: Mes 13\n",
    "\t2.Segunda Secuencia:\n",
    "    \t•Datos: Meses 2 a 13\n",
    "    \t•Etiqueta: Mes 14\n",
    "\t3.Continúa así hasta:\n",
    "    \t•Última Secuencia: Meses 24 a 35\n",
    "    \t•Etiqueta: Mes 36\n",
    "\n",
    "En total, tendrás 36 - 12 = 24 secuencias.\n",
    "\n",
    "Resumen\n",
    "\n",
    "\t•\tTienes datos de 36 meses.\n",
    "\t•\tUsas seq_length=12 para crear secuencias de 12 meses consecutivos.\n",
    "\t•\tCada secuencia de 12 meses predice el siguiente mes.\n",
    "\t•\tCreas un total de 24 secuencias de entrada.\n",
    "\n",
    "Espero que esto aclare cómo se utilizan los 12 períodos (seq_length=12) dentro de tus 36 meses de datos. Si necesitas ajustar este seq_length o tienes más preguntas, házmelo saber."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb07d42-68ca-452c-96e1-edcd911b475b",
   "metadata": {},
   "source": [
    "## Contenido de esta notebook:\n",
    "\n",
    "**1. Entrenamiento del Modelo Explicacion:**\n",
    "- process_and_train_model entrena el modelo LSTM con los datos proporcionados.\n",
    "- results contiene las predicciones para el último período disponible.\n",
    "\n",
    "**2. Guardado de Resultados:**\n",
    "- Se guarda el DataFrame results en un archivo CSV, renombrando tn_pred a tn.\n",
    "\n",
    "**3. Actualización del DataFrame df_ventas2:**\n",
    "- Se copia df_ventas en df_ventas2.\n",
    "- Se encuentra el último período y se calcula el siguiente.\n",
    "- Se copian los datos del último período al siguiente.\n",
    "- Se actualizan las tn del siguiente período con las predicciones de results.\n",
    "- Se elimina la columna pred_tn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22c266e0-d040-4830-afc8-cdd2341f7659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-----------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------\n",
      "    >>>>>>>>>>>>       Total Forecast Error: 4.50%     <<<<<<<<<<<<<<<<<<\n",
      "-----------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def calcular_total_forecast_error(actual, forecast):\n",
    "    \"\"\"\n",
    "    Calcula el Total Forecast Error dado un DataFrame con ventas reales y pronosticadas.\n",
    "\n",
    "    Parámetros:\n",
    "    actual (pd.Series): Serie con las ventas reales.\n",
    "    forecast (pd.Series): Serie con las ventas pronosticadas.\n",
    "\n",
    "    Retorna:\n",
    "    float: El Total Forecast Error.\n",
    "    \"\"\"\n",
    "    # Calcular el error absoluto\n",
    "    abs_error = abs(actual - forecast)\n",
    "    \n",
    "    # Calcular el Total Forecast Error\n",
    "    total_forecast_error = abs_error.sum() / actual.sum()\n",
    "    \n",
    "    print(\"\\n\\n-----------------------------------------------------------------------------\")\n",
    "    print(\"-----------------------------------------------------------------------------\")\n",
    "    print(f'    >>>>>>>>>>>>       Total Forecast Error: {total_forecast_error:.2%}     <<<<<<<<<<<<<<<<<<')\n",
    "    print(\"-----------------------------------------------------------------------------\")\n",
    "    print(\"-----------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "    \n",
    "    return total_forecast_error\n",
    "\n",
    "# Ejemplo de uso\n",
    "# Crear un DataFrame de ejemplo\n",
    "data = {\n",
    "    'product_id': [1, 2, 3, 4, 5],\n",
    "    'actual_sales': [100, 150, 200, 250, 300],\n",
    "    'forecast_sales': [110, 145, 190, 260, 310]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Calcular el Total Forecast Error\n",
    "tfe = calcular_total_forecast_error(df['actual_sales'], df['forecast_sales'])\n",
    "#print(\"\\n\\n-----------------------------------------------------------------------------\")\n",
    "#print(\"-----------------------------------------------------------------------------\")\n",
    "#print(f'    >>>>>>>>>>>>       Total Forecast Error: {tfe:.2%}     <<<<<<<<<<<<<<<<<<')\n",
    "#print(\"-----------------------------------------------------------------------------\")\n",
    "#print(\"-----------------------------------------------------------------------------\\n\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6ee447",
   "metadata": {},
   "source": [
    "# Funciones para calcular el tiempo de ejecucion del script completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3dd48eb-865a-4a27-b86e-cd9dca3bdedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# ---------------------------------------------------------------------------\n",
    "# Funciones para calcular el tiempo de ejecucion del script completo\n",
    "#\n",
    "# ---------------------------------------------------------------------------\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "def registrar_tiempo():\n",
    "    \"\"\"\n",
    "    Registra y devuelve el tiempo actual en un formato legible.\n",
    "\n",
    "    Retorna:\n",
    "    tuple: Una tupla con el objeto datetime y su representación en cadena.\n",
    "    \"\"\"\n",
    "    ahora = datetime.now()\n",
    "    ahora_str = ahora.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    return ahora, ahora_str\n",
    "\n",
    "def calcular_tiempo_transcurrido(inicio, fin):\n",
    "    \"\"\"\n",
    "    Calcula el tiempo transcurrido entre dos instantes.\n",
    "\n",
    "    Parámetros:\n",
    "    inicio (datetime): El tiempo de inicio.\n",
    "    fin (datetime): El tiempo de finalización.\n",
    "\n",
    "    Retorna:\n",
    "    float: El tiempo transcurrido en segundos.\n",
    "    \"\"\"\n",
    "    return (fin - inicio).total_seconds()\n",
    "\n",
    "\n",
    "# Registrar el tiempo de inicio al inicio del script\n",
    "#inicio, inicio_str = registrar_tiempo()\n",
    "\n",
    "\n",
    "# Registrar el tiempo de finalización al final del script\n",
    "#fin, fin_str = registrar_tiempo()\n",
    "\n",
    "# Calcular el tiempo transcurrido\n",
    "#tiempo_transcurrido = calcular_tiempo_transcurrido(inicio, fin)\n",
    "\n",
    "#print(f\"Tiempo de inicio: {inicio_str}\")\n",
    "#print(f\"Tiempo de finalización: {fin_str}\")\n",
    "#print(f\"Tiempo transcurrido: {tiempo_transcurrido} segundos\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc361bf",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# Funcion nombre_file(sfx)\n",
    "   - Genera el nombre del archivo .csv con prefijo datetime YYYY-MM-DD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdb284a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../666_Kaggle/Entregas/20240712-2102-MongoAurelio.csv\n",
      "Predicciones ajustadas guardadas en ../666_Kaggle/Entregas/20240712-2102-Sufijo-General_tfe2_0.1235.csv\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------\n",
    "# Funcion nombre_file(sfx)\n",
    "#   - Genera el nombre del archivo .csv con prefijo datetime YYYY-MM-DD\n",
    "from datetime import datetime\n",
    "def nombre_file(sfx):\n",
    "    # Obtener la fecha y hora actual en el formato requerido\n",
    "    current_time = datetime.now().strftime('%Y%m%d-%H%M-')\n",
    "\n",
    "    # Path to output dir\n",
    "    output_dir = '../666_Kaggle/Entregas/'    \n",
    "    return(output_dir+current_time+sfx+'.csv')\n",
    "\n",
    "\n",
    "# Indicar el nombre de la prueba\n",
    "suffix_name = 'MongoAurelio' \n",
    "\n",
    "file_to_kaggle = nombre_file(suffix_name)\n",
    "print(file_to_kaggle)\n",
    "\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Esto va al final para escribir el archivo final\n",
    "\n",
    "# Agrego el tfe2 al suffix del archivo\n",
    "#   Calculo del total forecast error\n",
    "#   tfe2 =  calcular_total_forecast_error(all_forecasts['y'], all_forecasts['yhat1'])\n",
    "#    print(f'Total Forecast Error: {tfe2:.2%}')\n",
    "\n",
    "tfe2 = 0.123456789\n",
    "str_tfe2 = \"_tfe2_\" + str(round(tfe2, 4)) \n",
    "\n",
    "# Suffijo general para las dos salidas de archivos\n",
    "#  Solo cambiar este valor\n",
    "suffix_general = 'Sufijo-General'  + str_tfe2\n",
    "\n",
    "# Usar la función nombre_file para asignar el nombre del archivo de salida para kaggle\n",
    "suffix_to_kaagle_name = suffix_general\n",
    "file_to_kaggle = nombre_file(suffix_to_kaagle_name)\n",
    "# Colocar el nombre del df apropiado\n",
    "#df_aGuardarEnDisco.to_csv(file_to_kaggle, index=False)\n",
    "\n",
    "#all_forecasts.to_csv(file_to_kaggle+'all', index=False)\n",
    "print(f'Predicciones ajustadas guardadas en {file_to_kaggle}')\n",
    "\n",
    "# Fin\n",
    "# ------------------------------------------------\n",
    "\n",
    "\n",
    "# Función para guardar los parámetros en un file\n",
    "import json\n",
    "def save_parameters(file_name, **params):\n",
    "    with open(file_name, 'w') as f:\n",
    "        json.dump(params, f, indent=4)\n",
    "# ------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7c3ba4",
   "metadata": {},
   "source": [
    "## Lecutura rapida de Dataset sell-z-780-all-LTSM.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38e65d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28080 entries, 0 to 28079\n",
      "Data columns (total 13 columns):\n",
      " #   Column                 Non-Null Count  Dtype         \n",
      "---  ------                 --------------  -----         \n",
      " 0   product_id             28080 non-null  int64         \n",
      " 1   periodo                28080 non-null  datetime64[ns]\n",
      " 2   plan_precios_cuidados  28080 non-null  float64       \n",
      " 3   cust_request_qty       28080 non-null  float64       \n",
      " 4   cust_request_tn        28080 non-null  float64       \n",
      " 5   tn                     28080 non-null  float64       \n",
      " 6   cant_periodos          28080 non-null  int64         \n",
      " 7   cat1                   28080 non-null  object        \n",
      " 8   cat2                   28080 non-null  object        \n",
      " 9   cat3                   28080 non-null  object        \n",
      " 10  brand                  28080 non-null  object        \n",
      " 11  sku_size               28080 non-null  int64         \n",
      " 12  descripcion            28080 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(4), int64(3), object(5)\n",
      "memory usage: 2.8+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>periodo</th>\n",
       "      <th>plan_precios_cuidados</th>\n",
       "      <th>cust_request_qty</th>\n",
       "      <th>cust_request_tn</th>\n",
       "      <th>tn</th>\n",
       "      <th>cant_periodos</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>brand</th>\n",
       "      <th>sku_size</th>\n",
       "      <th>descripcion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20001</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>479.0</td>\n",
       "      <td>937.72717</td>\n",
       "      <td>934.77222</td>\n",
       "      <td>36</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>ARIEL</td>\n",
       "      <td>3000</td>\n",
       "      <td>genoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20001</td>\n",
       "      <td>2017-02-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>432.0</td>\n",
       "      <td>833.72187</td>\n",
       "      <td>798.01620</td>\n",
       "      <td>36</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>ARIEL</td>\n",
       "      <td>3000</td>\n",
       "      <td>genoma</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id    periodo  plan_precios_cuidados  cust_request_qty  \\\n",
       "0       20001 2017-01-01                    0.0             479.0   \n",
       "1       20001 2017-02-01                    0.0             432.0   \n",
       "\n",
       "   cust_request_tn         tn  cant_periodos cat1         cat2     cat3  \\\n",
       "0        937.72717  934.77222             36   HC  ROPA LAVADO  Liquido   \n",
       "1        833.72187  798.01620             36   HC  ROPA LAVADO  Liquido   \n",
       "\n",
       "   brand  sku_size descripcion  \n",
       "0  ARIEL      3000      genoma  \n",
       "1  ARIEL      3000      genoma  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ventas_LTSM_path = '../66_Datos/sell-z-780-all-LTSM.csv'\n",
    "df_ventas = pd.read_csv(ventas_LTSM_path)\n",
    "\n",
    "# Convertir la columna 'periodo' a tipo datetime\n",
    "df_ventas['periodo'] = pd.to_datetime(df_ventas['periodo'], format='%Y-%m-%d')\n",
    "\n",
    "# Formatear la fecha según el formato deseado\n",
    "print(df_ventas.info())\n",
    "\n",
    "df_ventas.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4d26782-b9d4-46eb-8712-7db178cf1af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import legacy\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Verificar si hay GPUs disponibles\n",
    "#print(\"GPUs disponibles: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "# Configurar el uso de la GPU\n",
    "#gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "#if gpus:\n",
    "#    try:\n",
    "#        # Usar solo la primera GPU\n",
    "#        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "\n",
    "#        # Limitar el crecimiento de la memoria de la GPU\n",
    "#        for gpu in gpus:\n",
    "#            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        \n",
    "#        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "#        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "#    except RuntimeError as e:\n",
    "#        print(e)\n",
    "\n",
    "def calculate_weights(data):\n",
    "    total = np.sum(data)\n",
    "    weights = data / total\n",
    "    return weights\n",
    "\n",
    "\n",
    "def process_and_train_model(df_ventas, **kwargs):\n",
    "    seq_length = kwargs.get('seq_length', 12)\n",
    "    epochs = kwargs.get('epochs', 100)\n",
    "    batch_size = kwargs.get('batch_size', 32)\n",
    "    learning_rate = kwargs.get('learning_rate', 0.001)\n",
    "    patience = kwargs.get('patience', 20)\n",
    "    verbose = kwargs.get('verbose', 0)\n",
    "    seed = kwargs.get('seed', 52)\n",
    "    standard_scaler = kwargs.get('standard_scaler', 1) # 1 StandardScaler yes, 0 StandardScaler No\n",
    "\n",
    "    print(\" **** process_and_train_model()  ***** \")\n",
    "    print(\"   Cantidad de NaN en cat1: \", df_ventas['cat1'].isna().sum())\n",
    "    print(\" ********************************* \")\n",
    "\n",
    "    \n",
    "    \n",
    "    # Preparación de datos\n",
    "    df_full = df_ventas[['periodo', 'product_id', 'cat1', 'tn']].copy()\n",
    "    \n",
    "    # Identificar los valores cero antes de reemplazar\n",
    "    valores_cero_antes = df_full[df_full['tn'] == 0].copy()\n",
    "\n",
    "    # Calcular la media de 'tn' por 'product_id' y reemplazar los valores cero por esta media\n",
    "    mean_tn_by_product = df_full[df_full['tn'] != 0].groupby('product_id')['tn'].mean()\n",
    "    df_full.loc[df_full['tn'] == 0, 'tn'] = df_full['product_id'].map(mean_tn_by_product)\n",
    "\n",
    "    # Reemplazar NaN con la media global de tn\n",
    "    global_mean_tn = df_full['tn'].mean()\n",
    "    df_full['tn'].fillna(global_mean_tn, inplace=True)\n",
    "\n",
    "    # Aplicar la transformación logarítmica\n",
    "    df_full['tn'] = np.log1p(df_full['tn'])\n",
    "    \n",
    "    # Estandarización de datos\n",
    "    if standard_scaler == 1:\n",
    "        scaler = StandardScaler()\n",
    "        df_full['tn'] = scaler.fit_transform(df_full[['tn']])\n",
    "    \n",
    "    # Label Encoding para cat1\n",
    "    label_encoder = LabelEncoder()\n",
    "    df_full['cat1'] = label_encoder.fit_transform(df_full['cat1'])\n",
    "\n",
    "    def create_sequences(data, seq_length):\n",
    "        sequences = []\n",
    "        labels = []\n",
    "        for i in range(len(data) - seq_length):\n",
    "            seq_data = data.iloc[i:i + seq_length].values\n",
    "            sequences.append(seq_data)\n",
    "            labels.append(data.iloc[i + seq_length]['tn'])\n",
    "        return np.array(sequences), np.array(labels)\n",
    "\n",
    "    product_sequences = {}\n",
    "    weights_dict = {}\n",
    "    for product_id in df_full['product_id'].unique():\n",
    "        product_data = df_full[df_full['product_id'] == product_id].drop(columns=['product_id', 'periodo'])\n",
    "        sequences, labels = create_sequences(product_data, seq_length)\n",
    "        product_sequences[product_id] = (sequences, labels)\n",
    "        \n",
    "        # Calcular los pesos de las muestras\n",
    "        weights = calculate_weights(product_data['tn'].values[:len(sequences)])\n",
    "        weights_dict[product_id] = weights\n",
    "\n",
    "    # Preparar los datos de entrenamiento\n",
    "    X = np.concatenate([product_sequences[pid][0] for pid in product_sequences])\n",
    "    y = np.concatenate([product_sequences[pid][1] for pid in product_sequences])\n",
    "    product_ids = np.concatenate([[pid]*len(product_sequences[pid][1]) for pid in product_sequences])\n",
    "    \n",
    "    # Redimensionar los datos para que sean compatibles con LSTM\n",
    "    X = X.reshape(X.shape[0], X.shape[1], X.shape[2])\n",
    "\n",
    "    # Inicializar listas para almacenar las métricas de error\n",
    "    mae_list = []\n",
    "    rmse_list = []\n",
    "    mape_list = []\n",
    "    tfe_list = []\n",
    "\n",
    "    # Utilizar TimeSeriesSplit para dividir los datos\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    \n",
    "    all_product_ids = []\n",
    "    all_y_val = []\n",
    "    all_y_pred_val = []\n",
    "\n",
    "    for train_index, val_index in tscv.split(X):\n",
    "        X_train, X_val = X[train_index], X[val_index]\n",
    "        y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "        # Obtener los pesos de las muestras para el conjunto de entrenamiento y validación\n",
    "        sample_weights_train = np.concatenate([weights_dict[pid][:len(train_index)] for pid in product_sequences if pid in product_ids[train_index]])\n",
    "        sample_weights_val = np.concatenate([weights_dict[pid][:len(val_index)] for pid in product_sequences if pid in product_ids[val_index]])\n",
    "\n",
    "        # Verificar los tamaños antes de model.fit\n",
    "        #print(f\"X_train.shape: {X_train.shape}\")\n",
    "        #print(f\"y_train.shape: {y_train.shape}\")\n",
    "        #print(f\"sample_weights_train.shape: {sample_weights_train.shape}\")\n",
    "        #print(f\"X_val.shape: {X_val.shape}\")\n",
    "        #print(f\"y_val.shape: {y_val.shape}\")\n",
    "        #∫print(f\"sample_weights_val.shape: {sample_weights_val.shape}\")\n",
    "\n",
    "        model = Sequential([\n",
    "            LSTM(50, return_sequences=True, input_shape=(seq_length, X.shape[2])),  # Primera capa LSTM\n",
    "            LSTM(50, return_sequences=False),  # Segunda capa LSTM\n",
    "            Dropout(0.2),  # Mantener el dropout para regularización\n",
    "            Dense(25, activation='relu'),  # Reducir el tamaño de la capa densa\n",
    "            Dense(1)  # Capa de salida\n",
    "        ])\n",
    "        \n",
    "        optimizer = legacy.Adam(learning_rate=learning_rate)\n",
    "        model.compile(optimizer=optimizer, loss='mean_squared_error', weighted_metrics=['mae'])\n",
    "\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=patience, restore_best_weights=True)\n",
    "        reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6, verbose=0)\n",
    "\n",
    "        history = model.fit(X_train, y_train, sample_weight=sample_weights_train, epochs=epochs, batch_size=batch_size, validation_data=(X_val, y_val, sample_weights_val), callbacks=[early_stopping, reduce_lr], verbose=verbose)\n",
    "\n",
    "        # Generar predicciones para el split actual\n",
    "        y_pred_val = model.predict(X_val)\n",
    "\n",
    "        y_val = y_val.reshape(-1, 1)\n",
    "        y_pred_val = y_pred_val.reshape(-1, 1)\n",
    "        \n",
    "        # Invertir normalizacion StandarScarler si esta fue seleccionada.\n",
    "        if standard_scaler == 1:\n",
    "            y_pred_val = scaler.inverse_transform(y_pred_val)\n",
    "            y_val = scaler.inverse_transform(y_val)\n",
    "\n",
    "        # Invertir la transformación logarítmica para los valores de validación y predicción\n",
    "        y_pred_val = np.expm1(y_pred_val)\n",
    "        y_val = np.expm1(y_val)\n",
    "\n",
    "        # Calcular las métricas de error para el split actual\n",
    "        mae = mean_absolute_error(y_val, y_pred_val)\n",
    "        rmse = np.sqrt(mean_squared_error(y_val, y_pred_val))\n",
    "        mape = np.mean(np.abs((y_val - y_pred_val) / y_val)) * 100\n",
    "        tfe = np.sum(np.abs(y_val - y_pred_val)) / np.sum(np.abs(y_val))\n",
    "\n",
    "        # Almacenar las métricas en las listas correspondientes\n",
    "        mae_list.append(mae)\n",
    "        rmse_list.append(rmse)\n",
    "        mape_list.append(mape)\n",
    "        tfe_list.append(tfe)\n",
    "\n",
    "        all_product_ids.extend(product_ids[val_index])\n",
    "        all_y_val.extend(y_val)\n",
    "        all_y_pred_val.extend(y_pred_val)\n",
    "\n",
    "    \n",
    "    avg_mae = np.mean(mae_list)\n",
    "    avg_rmse = np.mean(rmse_list)\n",
    "    avg_mape = np.mean(mape_list)\n",
    "    avg_tfe = np.mean(tfe_list)\n",
    "\n",
    "    # Generar predicciones finales con el modelo entrenado\n",
    "    X_pred = np.array([product_sequences[pid][0][-1] for pid in product_sequences])\n",
    "    predictions = model.predict(X_pred)\n",
    "    \n",
    "    # Invertir normalizacion StandarScarler si esta fue seleccionada.\n",
    "    if standard_scaler == 1:\n",
    "        predictions = scaler.inverse_transform(predictions)\n",
    "    \n",
    "    # Invertir la transformación logarítmica\n",
    "    predictions = np.expm1(predictions)\n",
    "\n",
    "    final_predictions = pd.DataFrame({\n",
    "        'product_id': df_full['product_id'].unique(),\n",
    "        'tn_pred': predictions.flatten()\n",
    "    })\n",
    "\n",
    "    final_product_ids = np.array(all_product_ids)\n",
    "    final_y_val = np.array(all_y_val)\n",
    "    final_y_pred_val = np.array(all_y_pred_val)\n",
    "\n",
    "    # Asegurarse de que todos los productos están presentes en all_results\n",
    "    all_results = pd.DataFrame({\n",
    "        'product_id': final_product_ids,\n",
    "        'y_val': final_y_val.flatten(),\n",
    "        'y_pred_val': final_y_pred_val.flatten()\n",
    "    })\n",
    "\n",
    "    # Devolver las métricas promedio junto con las predicciones y resultados de validación\n",
    "    metrics = {\n",
    "        'avg_mae': avg_mae,\n",
    "        'avg_rmse': avg_rmse,\n",
    "        'avg_mape': avg_mape,\n",
    "        'avg_tfe': avg_tfe\n",
    "    }\n",
    "    \n",
    "    return final_predictions, all_results, weights_dict, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "394f399c-6d0c-49e7-9b12-4c0ce79061dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def master_of_the_universe():\n",
    "    # --------------------------------------------------------------------------\n",
    "    #  Salida Prediccion Enero 2020\n",
    "    # --------------------------------------------------------------------------\n",
    "\n",
    "    # Llama a la función con el diccionario de parámetros\n",
    "    results, df_errors_sorted, weights_dict, metrics = process_and_train_model(df_ventas, **parameters)\n",
    "\n",
    "    # Ahora guarda los resultados como de costumbre\n",
    "    results_toCsv = results.copy()\n",
    "    results_toCsv = results_toCsv.rename(columns={'tn_pred': 'tn'})\n",
    "\n",
    "    # Guardar el archivo final\n",
    "    #suffix_general = 'LSTM_v8v4_ene' + \"_tfe2_\" + str(round(metrics['avg_tfe'], 4))\n",
    "    #file_to_kaggle = nombre_file(suffix_general)\n",
    "    #results_toCsv.to_csv(file_to_kaggle, index=False)\n",
    "\n",
    "    # Calcula las métricas para noviembre y diciembre 2019\n",
    "    #mae_nov_dec_2019 = mean_absolute_error(df_errors_sorted['y_val'], df_errors_sorted['y_pred_val'])\n",
    "    #rmse_nov_dec_2019 = np.sqrt(mean_squared_error(df_errors_sorted['y_val'], df_errors_sorted['y_pred_val']))\n",
    "    #mape_nov_dec_2019 = np.mean(np.abs((df_errors_sorted['y_val'] - df_errors_sorted['y_pred_val']) / df_errors_sorted['y_val'])) * 100\n",
    "    #tfe_nov_dec_2019 = calcular_total_forecast_error(df_errors_sorted['y_val'], df_errors_sorted['y_pred_val'])\n",
    "\n",
    "    # Combina las métricas con los parámetros\n",
    "    #metrics_combined = {\n",
    "    #    \"validation\": {\n",
    "    #        \"avg_mae\": metrics[\"avg_mae\"],\n",
    "    #        \"avg_rmse\": metrics[\"avg_rmse\"],\n",
    "    #        \"avg_mape\": metrics[\"avg_mape\"],\n",
    "    #        \"avg_tfe\": metrics[\"avg_tfe\"]\n",
    "    #    },\n",
    "    #    \"future_predictions\": {\n",
    "    #        \"mae_nov_dec_2019\": mae_nov_dec_2019,\n",
    "    #        \"rmse_nov_dec_2019\": rmse_nov_dec_2019,\n",
    "    #        \"mape_nov_dec_2019\": mape_nov_dec_2019,\n",
    "    #        \"tfe_nov_dec_2019\": tfe_nov_dec_2019\n",
    "    #    }\n",
    "    #}\n",
    "    #metrics_combined.update(parameters)\n",
    "\n",
    "    # Guardar las métricas y parámetros en un archivo JSON\n",
    "    #metrics_file = file_to_kaggle + \".metrics.json\"\n",
    "    #save_parameters(metrics_file, **metrics_combined)\n",
    "\n",
    "    #print(f'Predicciones ajustadas guardadas en {file_to_kaggle}')\n",
    "    #print(f'Métricas y parámetros guardados en {metrics_file}')\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    #  Salida Prediccion Febrero 2020\n",
    "    # --------------------------------------------------------------------------\n",
    "\n",
    "    # Calcular el siguiente período (suponiendo que los periodos son mensuales)\n",
    "    df_ventas['periodo'] = pd.to_datetime(df_ventas['periodo'], format='%Y%m')\n",
    "    ultimo_periodo = df_ventas['periodo'].max()\n",
    "    siguiente_periodo = ultimo_periodo + pd.DateOffset(months=1)\n",
    "\n",
    "    # Actualizar las 'tn' del siguiente período con las 'tn' de results\n",
    "    df_ventas['periodo'] = df_ventas['periodo'].dt.strftime('%Y%m')\n",
    "    results_toCsv['periodo'] = siguiente_periodo.strftime('%Y%m')\n",
    "    df_ventas2 = pd.concat([df_ventas, results_toCsv], ignore_index=True)\n",
    "\n",
    "    # Vuelvo a convertir a 'periodo' a tipo datetime\n",
    "    df_ventas['periodo'] = pd.to_datetime(df_ventas['periodo'], format='%Y%m')\n",
    "    df_ventas2['periodo'] = pd.to_datetime(df_ventas2['periodo'], format='%Y%m')\n",
    "    df_ventas['periodo'] = df_ventas['periodo'].dt.strftime('%Y-%m-%d')\n",
    "    df_ventas2['periodo'] = df_ventas2['periodo'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "    # Para el periodo agregado a df_ventas2 los valores para cat1 (y otros atributos) son completados con NaN.\n",
    "    # Las siguientes lineas reemplazan en cat1 los valores NaN del periodo agregado a df_ventas con su código correspondiente.\n",
    "    df_referencia = df_ventas2[['product_id', 'cat1']].dropna().drop_duplicates()\n",
    "    cat1_mapping = df_referencia.set_index('product_id')['cat1'].to_dict()\n",
    "    df_ventas2['cat1'] = df_ventas2['cat1'].fillna(df_ventas2['product_id'].map(cat1_mapping))\n",
    "\n",
    "    print(\" **** Master of the Universe ***** \")\n",
    "    print(\"   Cantidad de NaN en cat1: \", df_ventas2['cat1'].isna().sum())\n",
    "    print(\" ********************************* \")\n",
    "\n",
    "    # Entrenar el modelo con datos hasta el último período actualizado\n",
    "    results2, df_errors_sorted2, weights_dict2, metrics2 = process_and_train_model(df_ventas2, **parameters)\n",
    "    results2 = results2.rename(columns=({'tn_pred': 'tn'}))\n",
    "\n",
    "    # Guardar el archivo final\n",
    "    suffix_general = 'LSTM_v8v4_feb' + \"_tfe2_\" + str(round(metrics2['avg_tfe'], 4))\n",
    "    file_to_kaggle = nombre_file(suffix_general)\n",
    "    results2.to_csv(file_to_kaggle, index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Verificar si hay valores infinitos o NaN\n",
    "    print(\" -----------------------------------------------\")\n",
    "    print(\"  Verificando valores infinitos\")\n",
    "    print(np.isinf(df_errors_sorted2['y_pred_val']).sum())\n",
    "    print(np.isnan(df_errors_sorted2['y_pred_val']).sum())\n",
    "    print(np.isinf(df_errors_sorted2['y_val']).sum())\n",
    "    print(np.isnan(df_errors_sorted2['y_val']).sum())\n",
    "    \n",
    "\n",
    "    # Reemplaza infinitos con valores grandes finitos\n",
    "    df_errors_sorted2['y_pred_val'] = np.where(np.isinf(df_errors_sorted2['y_pred_val']), np.finfo(np.float32).max, df_errors_sorted2['y_pred_val'])\n",
    "    df_errors_sorted2['y_val'] = np.where(np.isinf(df_errors_sorted2['y_val']), np.finfo(np.float32).max, df_errors_sorted2['y_val'])\n",
    "\n",
    "    # Reemplaza NaN con el promedio o con 0, dependiendo del caso\n",
    "    df_errors_sorted2['y_pred_val'].fillna(df_errors_sorted2['y_pred_val'].mean(), inplace=True)\n",
    "    df_errors_sorted2['y_val'].fillna(df_errors_sorted2['y_val'].mean(), inplace=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Calcula las métricas para noviembre y diciembre 2019\n",
    "    mae_nov_dec_2019_2 = mean_absolute_error(df_errors_sorted2['y_val'], df_errors_sorted2['y_pred_val'])\n",
    "    rmse_nov_dec_2019_2 = np.sqrt(mean_squared_error(df_errors_sorted2['y_val'], df_errors_sorted2['y_pred_val']))\n",
    "    mape_nov_dec_2019_2 = np.mean(np.abs((df_errors_sorted2['y_val'] - df_errors_sorted2['y_pred_val']) / df_errors_sorted2['y_val'])) * 100\n",
    "    tfe_nov_dec_2019_2 = calcular_total_forecast_error(df_errors_sorted2['y_val'], df_errors_sorted2['y_pred_val'])\n",
    "\n",
    "    # Combina las métricas con los parámetros\n",
    "    metrics_combined_2 = {\n",
    "        \"validation\": {\n",
    "            \"avg_mae\": metrics2[\"avg_mae\"],\n",
    "            \"avg_rmse\": metrics2[\"avg_rmse\"],\n",
    "            \"avg_mape\": metrics2[\"avg_mape\"],\n",
    "            \"avg_tfe\": metrics2[\"avg_tfe\"]\n",
    "        },\n",
    "        \"future_predictions\": {\n",
    "            \"mae_nov_dec_2019\": mae_nov_dec_2019_2,\n",
    "            \"rmse_nov_dec_2019\": rmse_nov_dec_2019_2,\n",
    "            \"mape_nov_dec_2019\": mape_nov_dec_2019_2,\n",
    "            \"tfe_nov_dec_2019\": tfe_nov_dec_2019_2\n",
    "        }\n",
    "    }\n",
    "    metrics_combined_2.update(parameters)\n",
    "\n",
    "    # Guardar las métricas y parámetros en un archivo JSON\n",
    "    metrics_file_2 = file_to_kaggle + \".metrics.json\"\n",
    "    save_parameters(metrics_file_2, **metrics_combined_2)\n",
    "\n",
    "    print(f'Predicciones ajustadas guardadas en {file_to_kaggle}')\n",
    "    print(f'Métricas y parámetros guardados en {metrics_file_2}')\n",
    "\n",
    "    return df_ventas2, weights_dict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b3a423a-ad83-45b9-b855-5fc3fc177ce8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de combinaciones: 16\n",
      "\n",
      "\n",
      "# -------------------------------------------------------------------------------------------------------------------\n",
      "# Tiempo de Ejecucion:\n",
      "#    Tiempo de inicio: 2024-07-13 08:15:25\n",
      "#    Tiempo de actual: 2024-07-13 08:15:25\n",
      "# \n",
      "#    Tiempo transcurrido: 0.483636 segundos\n",
      "# \n",
      "# LSTM Parameters:\n",
      "#   seed=52, seq_length=3, epochs=50, batch_size=32, learning_rate=0.0001, patience=10, verbose=0, standard_scaler=1 \n",
      "# -------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      " **** process_and_train_model()  ***** \n",
      "   Cantidad de NaN en cat1:  0\n",
      " ********************************* \n",
      "135/135 [==============================] - 0s 576us/step\n",
      "135/135 [==============================] - 0s 591us/step\n",
      "135/135 [==============================] - 0s 578us/step\n",
      "135/135 [==============================] - 0s 578us/step\n",
      "135/135 [==============================] - 0s 578us/step\n",
      "25/25 [==============================] - 0s 553us/step\n",
      " **** Master of the Universe ***** \n",
      "   Cantidad de NaN en cat1:  0\n",
      " ********************************* \n",
      " **** process_and_train_model()  ***** \n",
      "   Cantidad de NaN en cat1:  0\n",
      " ********************************* \n",
      "139/139 [==============================] - 0s 575us/step\n",
      "139/139 [==============================] - 0s 587us/step\n",
      "139/139 [==============================] - 0s 581us/step\n",
      "139/139 [==============================] - 0s 571us/step\n",
      "139/139 [==============================] - 0s 572us/step\n",
      "25/25 [==============================] - 0s 525us/step\n",
      " -----------------------------------------------\n",
      "  Verificando valores infinitos\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "\n",
      "\n",
      "-----------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------\n",
      "    >>>>>>>>>>>>       Total Forecast Error: 36.61%     <<<<<<<<<<<<<<<<<<\n",
      "-----------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Predicciones ajustadas guardadas en ../666_Kaggle/Entregas/20240713-0817-LSTM_v8v4_feb_tfe2_0.436.csv\n",
      "Métricas y parámetros guardados en ../666_Kaggle/Entregas/20240713-0817-LSTM_v8v4_feb_tfe2_0.436.csv.metrics.json\n",
      "\n",
      "\n",
      "# -------------------------------------------------------------------------------------------------------------------\n",
      "# Tiempo de Ejecucion:\n",
      "#    Tiempo de inicio: 2024-07-13 08:15:25\n",
      "#    Tiempo de actual: 2024-07-13 08:17:54\n",
      "# \n",
      "#    Tiempo transcurrido: 149.702521 segundos\n",
      "# \n",
      "# LSTM Parameters:\n",
      "#   seed=52, seq_length=6, epochs=50, batch_size=32, learning_rate=0.0001, patience=10, verbose=0, standard_scaler=1 \n",
      "# -------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      " **** process_and_train_model()  ***** \n",
      "   Cantidad de NaN en cat1:  0\n",
      " ********************************* \n",
      "122/122 [==============================] - 0s 784us/step\n",
      "122/122 [==============================] - 0s 777us/step\n",
      "122/122 [==============================] - 0s 800us/step\n",
      "122/122 [==============================] - 0s 793us/step\n",
      "122/122 [==============================] - 0s 793us/step\n",
      "25/25 [==============================] - 0s 737us/step\n",
      " **** Master of the Universe ***** \n",
      "   Cantidad de NaN en cat1:  0\n",
      " ********************************* \n",
      " **** process_and_train_model()  ***** \n",
      "   Cantidad de NaN en cat1:  0\n",
      " ********************************* \n",
      "126/126 [==============================] - 0s 771us/step\n",
      "126/126 [==============================] - 0s 799us/step\n",
      "126/126 [==============================] - 0s 766us/step\n",
      "126/126 [==============================] - 0s 793us/step\n",
      "126/126 [==============================] - 0s 798us/step\n",
      "25/25 [==============================] - 0s 729us/step\n",
      " -----------------------------------------------\n",
      "  Verificando valores infinitos\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "\n",
      "\n",
      "-----------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------\n",
      "    >>>>>>>>>>>>       Total Forecast Error: 32.21%     <<<<<<<<<<<<<<<<<<\n",
      "-----------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Predicciones ajustadas guardadas en ../666_Kaggle/Entregas/20240713-0821-LSTM_v8v4_feb_tfe2_0.4665.csv\n",
      "Métricas y parámetros guardados en ../666_Kaggle/Entregas/20240713-0821-LSTM_v8v4_feb_tfe2_0.4665.csv.metrics.json\n",
      "\n",
      "\n",
      "# -------------------------------------------------------------------------------------------------------------------\n",
      "# Tiempo de Ejecucion:\n",
      "#    Tiempo de inicio: 2024-07-13 08:15:25\n",
      "#    Tiempo de actual: 2024-07-13 08:21:42\n",
      "# \n",
      "#    Tiempo transcurrido: 376.776035 segundos\n",
      "# \n",
      "# LSTM Parameters:\n",
      "#   seed=52, seq_length=3, epochs=50, batch_size=64, learning_rate=0.0001, patience=10, verbose=0, standard_scaler=1 \n",
      "# -------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      " **** process_and_train_model()  ***** \n",
      "   Cantidad de NaN en cat1:  0\n",
      " ********************************* \n",
      "135/135 [==============================] - 0s 593us/step\n",
      "135/135 [==============================] - 0s 580us/step\n",
      "135/135 [==============================] - 0s 595us/step\n",
      "135/135 [==============================] - 0s 620us/step\n",
      "135/135 [==============================] - 0s 588us/step\n",
      "25/25 [==============================] - 0s 521us/step\n",
      " **** Master of the Universe ***** \n",
      "   Cantidad de NaN en cat1:  0\n",
      " ********************************* \n",
      " **** process_and_train_model()  ***** \n",
      "   Cantidad de NaN en cat1:  0\n",
      " ********************************* \n",
      "139/139 [==============================] - 0s 601us/step\n",
      "139/139 [==============================] - 0s 584us/step\n",
      "139/139 [==============================] - 0s 607us/step\n",
      "139/139 [==============================] - 0s 604us/step\n",
      "139/139 [==============================] - 0s 585us/step\n",
      "25/25 [==============================] - 0s 551us/step\n",
      " -----------------------------------------------\n",
      "  Verificando valores infinitos\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "\n",
      "\n",
      "-----------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------\n",
      "    >>>>>>>>>>>>       Total Forecast Error: 35.79%     <<<<<<<<<<<<<<<<<<\n",
      "-----------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Predicciones ajustadas guardadas en ../666_Kaggle/Entregas/20240713-0823-LSTM_v8v4_feb_tfe2_0.4304.csv\n",
      "Métricas y parámetros guardados en ../666_Kaggle/Entregas/20240713-0823-LSTM_v8v4_feb_tfe2_0.4304.csv.metrics.json\n",
      "\n",
      "\n",
      "# -------------------------------------------------------------------------------------------------------------------\n",
      "# Tiempo de Ejecucion:\n",
      "#    Tiempo de inicio: 2024-07-13 08:15:25\n",
      "#    Tiempo de actual: 2024-07-13 08:23:51\n",
      "# \n",
      "#    Tiempo transcurrido: 506.221213 segundos\n",
      "# \n",
      "# LSTM Parameters:\n",
      "#   seed=52, seq_length=6, epochs=50, batch_size=64, learning_rate=0.0001, patience=10, verbose=0, standard_scaler=1 \n",
      "# -------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      " **** process_and_train_model()  ***** \n",
      "   Cantidad de NaN en cat1:  0\n",
      " ********************************* \n",
      "122/122 [==============================] - 0s 787us/step\n",
      "122/122 [==============================] - 0s 1ms/step\n",
      "122/122 [==============================] - 0s 772us/step\n",
      "122/122 [==============================] - 0s 779us/step\n",
      "122/122 [==============================] - 0s 798us/step\n",
      "25/25 [==============================] - 0s 727us/step\n",
      " **** Master of the Universe ***** \n",
      "   Cantidad de NaN en cat1:  0\n",
      " ********************************* \n",
      " **** process_and_train_model()  ***** \n",
      "   Cantidad de NaN en cat1:  0\n",
      " ********************************* \n",
      "126/126 [==============================] - 0s 803us/step\n",
      "126/126 [==============================] - 0s 796us/step\n",
      "126/126 [==============================] - 0s 787us/step\n",
      "126/126 [==============================] - 0s 820us/step\n",
      "126/126 [==============================] - 0s 793us/step\n",
      "25/25 [==============================] - 0s 733us/step\n",
      " -----------------------------------------------\n",
      "  Verificando valores infinitos\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "\n",
      "\n",
      "-----------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------\n",
      "    >>>>>>>>>>>>       Total Forecast Error: 34.86%     <<<<<<<<<<<<<<<<<<\n",
      "-----------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Predicciones ajustadas guardadas en ../666_Kaggle/Entregas/20240713-0826-LSTM_v8v4_feb_tfe2_0.4981.csv\n",
      "Métricas y parámetros guardados en ../666_Kaggle/Entregas/20240713-0826-LSTM_v8v4_feb_tfe2_0.4981.csv.metrics.json\n",
      "\n",
      "\n",
      "# -------------------------------------------------------------------------------------------------------------------\n",
      "# Tiempo de Ejecucion:\n",
      "#    Tiempo de inicio: 2024-07-13 08:15:25\n",
      "#    Tiempo de actual: 2024-07-13 08:26:40\n",
      "# \n",
      "#    Tiempo transcurrido: 675.502022 segundos\n",
      "# \n",
      "# LSTM Parameters:\n",
      "#   seed=52, seq_length=3, epochs=20, batch_size=32, learning_rate=0.0001, patience=10, verbose=0, standard_scaler=1 \n",
      "# -------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      " **** process_and_train_model()  ***** \n",
      "   Cantidad de NaN en cat1:  0\n",
      " ********************************* \n",
      "135/135 [==============================] - 0s 594us/step\n",
      "135/135 [==============================] - 0s 584us/step\n",
      "135/135 [==============================] - 0s 590us/step\n",
      "135/135 [==============================] - 0s 595us/step\n",
      "135/135 [==============================] - 0s 580us/step\n",
      "25/25 [==============================] - 0s 539us/step\n",
      " **** Master of the Universe ***** \n",
      "   Cantidad de NaN en cat1:  0\n",
      " ********************************* \n",
      " **** process_and_train_model()  ***** \n",
      "   Cantidad de NaN en cat1:  0\n",
      " ********************************* \n",
      "139/139 [==============================] - 0s 588us/step\n",
      "139/139 [==============================] - 0s 591us/step\n",
      "139/139 [==============================] - 0s 589us/step\n",
      "139/139 [==============================] - 0s 838us/step\n",
      "139/139 [==============================] - 0s 595us/step\n",
      "25/25 [==============================] - 0s 547us/step\n",
      " -----------------------------------------------\n",
      "  Verificando valores infinitos\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "\n",
      "\n",
      "-----------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------\n",
      "    >>>>>>>>>>>>       Total Forecast Error: 39.46%     <<<<<<<<<<<<<<<<<<\n",
      "-----------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Predicciones ajustadas guardadas en ../666_Kaggle/Entregas/20240713-0828-LSTM_v8v4_feb_tfe2_0.4415.csv\n",
      "Métricas y parámetros guardados en ../666_Kaggle/Entregas/20240713-0828-LSTM_v8v4_feb_tfe2_0.4415.csv.metrics.json\n",
      "\n",
      "\n",
      "# -------------------------------------------------------------------------------------------------------------------\n",
      "# Tiempo de Ejecucion:\n",
      "#    Tiempo de inicio: 2024-07-13 08:15:25\n",
      "#    Tiempo de actual: 2024-07-13 08:28:55\n",
      "# \n",
      "#    Tiempo transcurrido: 809.880281 segundos\n",
      "# \n",
      "# LSTM Parameters:\n",
      "#   seed=52, seq_length=6, epochs=20, batch_size=32, learning_rate=0.0001, patience=10, verbose=0, standard_scaler=1 \n",
      "# -------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      " **** process_and_train_model()  ***** \n",
      "   Cantidad de NaN en cat1:  0\n",
      " ********************************* \n",
      "122/122 [==============================] - 0s 800us/step\n",
      "122/122 [==============================] - 0s 791us/step\n",
      "122/122 [==============================] - 0s 786us/step\n",
      "122/122 [==============================] - 0s 942us/step\n",
      "122/122 [==============================] - 0s 779us/step\n",
      "25/25 [==============================] - 0s 835us/step\n",
      " **** Master of the Universe ***** \n",
      "   Cantidad de NaN en cat1:  0\n",
      " ********************************* \n",
      " **** process_and_train_model()  ***** \n",
      "   Cantidad de NaN en cat1:  0\n",
      " ********************************* \n",
      "126/126 [==============================] - 0s 792us/step\n",
      "126/126 [==============================] - 0s 799us/step\n",
      "126/126 [==============================] - 0s 816us/step\n",
      "126/126 [==============================] - 0s 793us/step\n",
      "126/126 [==============================] - 0s 820us/step\n",
      "25/25 [==============================] - 0s 778us/step\n",
      " -----------------------------------------------\n",
      "  Verificando valores infinitos\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "\n",
      "\n",
      "-----------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------\n",
      "    >>>>>>>>>>>>       Total Forecast Error: 33.44%     <<<<<<<<<<<<<<<<<<\n",
      "-----------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Predicciones ajustadas guardadas en ../666_Kaggle/Entregas/20240713-0832-LSTM_v8v4_feb_tfe2_0.4835.csv\n",
      "Métricas y parámetros guardados en ../666_Kaggle/Entregas/20240713-0832-LSTM_v8v4_feb_tfe2_0.4835.csv.metrics.json\n",
      "\n",
      "\n",
      "# -------------------------------------------------------------------------------------------------------------------\n",
      "# Tiempo de Ejecucion:\n",
      "#    Tiempo de inicio: 2024-07-13 08:15:25\n",
      "#    Tiempo de actual: 2024-07-13 08:32:16\n",
      "# \n",
      "#    Tiempo transcurrido: 1011.23976 segundos\n",
      "# \n",
      "# LSTM Parameters:\n",
      "#   seed=52, seq_length=3, epochs=20, batch_size=64, learning_rate=0.0001, patience=10, verbose=0, standard_scaler=1 \n",
      "# -------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      " **** process_and_train_model()  ***** \n",
      "   Cantidad de NaN en cat1:  0\n",
      " ********************************* \n",
      "135/135 [==============================] - 0s 593us/step\n",
      "135/135 [==============================] - 0s 820us/step\n",
      "135/135 [==============================] - 0s 596us/step\n",
      "135/135 [==============================] - 0s 591us/step\n",
      "135/135 [==============================] - 0s 595us/step\n",
      "25/25 [==============================] - 0s 546us/step\n",
      " **** Master of the Universe ***** \n",
      "   Cantidad de NaN en cat1:  0\n",
      " ********************************* \n",
      " **** process_and_train_model()  ***** \n",
      "   Cantidad de NaN en cat1:  0\n",
      " ********************************* \n",
      "139/139 [==============================] - 0s 605us/step\n",
      "139/139 [==============================] - 0s 604us/step\n",
      "139/139 [==============================] - 0s 599us/step\n",
      "139/139 [==============================] - 0s 822us/step\n",
      "139/139 [==============================] - 0s 600us/step\n",
      "25/25 [==============================] - 0s 540us/step\n",
      " -----------------------------------------------\n",
      "  Verificando valores infinitos\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "\n",
      "\n",
      "-----------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------\n",
      "    >>>>>>>>>>>>       Total Forecast Error: 37.97%     <<<<<<<<<<<<<<<<<<\n",
      "-----------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Predicciones ajustadas guardadas en ../666_Kaggle/Entregas/20240713-0833-LSTM_v8v4_feb_tfe2_0.4615.csv\n",
      "Métricas y parámetros guardados en ../666_Kaggle/Entregas/20240713-0833-LSTM_v8v4_feb_tfe2_0.4615.csv.metrics.json\n",
      "\n",
      "\n",
      "# -------------------------------------------------------------------------------------------------------------------\n",
      "# Tiempo de Ejecucion:\n",
      "#    Tiempo de inicio: 2024-07-13 08:15:25\n",
      "#    Tiempo de actual: 2024-07-13 08:33:55\n",
      "# \n",
      "#    Tiempo transcurrido: 1110.647421 segundos\n",
      "# \n",
      "# LSTM Parameters:\n",
      "#   seed=52, seq_length=6, epochs=20, batch_size=64, learning_rate=0.0001, patience=10, verbose=0, standard_scaler=1 \n",
      "# -------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      " **** process_and_train_model()  ***** \n",
      "   Cantidad de NaN en cat1:  0\n",
      " ********************************* \n",
      "122/122 [==============================] - 0s 813us/step\n",
      "122/122 [==============================] - 0s 799us/step\n",
      "122/122 [==============================] - 0s 799us/step\n",
      "122/122 [==============================] - 0s 796us/step\n",
      "122/122 [==============================] - 0s 789us/step\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      " **** Master of the Universe ***** \n",
      "   Cantidad de NaN en cat1:  0\n",
      " ********************************* \n",
      " **** process_and_train_model()  ***** \n",
      "   Cantidad de NaN en cat1:  0\n",
      " ********************************* \n",
      "126/126 [==============================] - 0s 853us/step\n",
      "126/126 [==============================] - 0s 817us/step\n",
      "126/126 [==============================] - 0s 803us/step\n",
      "126/126 [==============================] - 0s 815us/step\n",
      "126/126 [==============================] - 0s 830us/step\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      " -----------------------------------------------\n",
      "  Verificando valores infinitos\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "\n",
      "\n",
      "-----------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------\n",
      "    >>>>>>>>>>>>       Total Forecast Error: 36.52%     <<<<<<<<<<<<<<<<<<\n",
      "-----------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Predicciones ajustadas guardadas en ../666_Kaggle/Entregas/20240713-0836-LSTM_v8v4_feb_tfe2_0.5224.csv\n",
      "Métricas y parámetros guardados en ../666_Kaggle/Entregas/20240713-0836-LSTM_v8v4_feb_tfe2_0.5224.csv.metrics.json\n",
      "\n",
      "\n",
      "# -------------------------------------------------------------------------------------------------------------------\n",
      "# Tiempo de Ejecucion:\n",
      "#    Tiempo de inicio: 2024-07-13 08:15:25\n",
      "#    Tiempo de actual: 2024-07-13 08:36:06\n",
      "# \n",
      "#    Tiempo transcurrido: 1241.363488 segundos\n",
      "# \n",
      "# LSTM Parameters:\n",
      "#   seed=52, seq_length=3, epochs=50, batch_size=32, learning_rate=0.0001, patience=10, verbose=0, standard_scaler=0 \n",
      "# -------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      " **** process_and_train_model()  ***** \n",
      "   Cantidad de NaN en cat1:  0\n",
      " ********************************* \n",
      "135/135 [==============================] - 0s 605us/step\n",
      "135/135 [==============================] - 0s 602us/step\n",
      "135/135 [==============================] - 0s 611us/step\n",
      "135/135 [==============================] - 0s 601us/step\n",
      "135/135 [==============================] - 0s 817us/step\n",
      "25/25 [==============================] - 0s 618us/step\n",
      " **** Master of the Universe ***** \n",
      "   Cantidad de NaN en cat1:  0\n",
      " ********************************* \n",
      " **** process_and_train_model()  ***** \n",
      "   Cantidad de NaN en cat1:  0\n",
      " ********************************* \n",
      "139/139 [==============================] - 0s 798us/step\n",
      "139/139 [==============================] - 0s 583us/step\n",
      "139/139 [==============================] - 0s 583us/step\n",
      "139/139 [==============================] - 0s 606us/step\n",
      "139/139 [==============================] - 0s 605us/step\n",
      "25/25 [==============================] - 0s 549us/step\n",
      " -----------------------------------------------\n",
      "  Verificando valores infinitos\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "\n",
      "\n",
      "-----------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------\n",
      "    >>>>>>>>>>>>       Total Forecast Error: 26.69%     <<<<<<<<<<<<<<<<<<\n",
      "-----------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Predicciones ajustadas guardadas en ../666_Kaggle/Entregas/20240713-0839-LSTM_v8v4_feb_tfe2_0.289.csv\n",
      "Métricas y parámetros guardados en ../666_Kaggle/Entregas/20240713-0839-LSTM_v8v4_feb_tfe2_0.289.csv.metrics.json\n",
      "\n",
      "\n",
      "# -------------------------------------------------------------------------------------------------------------------\n",
      "# Tiempo de Ejecucion:\n",
      "#    Tiempo de inicio: 2024-07-13 08:15:25\n",
      "#    Tiempo de actual: 2024-07-13 08:39:52\n",
      "# \n",
      "#    Tiempo transcurrido: 1467.097551 segundos\n",
      "# \n",
      "# LSTM Parameters:\n",
      "#   seed=52, seq_length=6, epochs=50, batch_size=32, learning_rate=0.0001, patience=10, verbose=0, standard_scaler=0 \n",
      "# -------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      " **** process_and_train_model()  ***** \n",
      "   Cantidad de NaN en cat1:  0\n",
      " ********************************* \n",
      "122/122 [==============================] - 0s 853us/step\n",
      "122/122 [==============================] - 0s 808us/step\n",
      "122/122 [==============================] - 0s 819us/step\n",
      "122/122 [==============================] - 0s 1ms/step\n",
      "122/122 [==============================] - 0s 794us/step\n",
      "25/25 [==============================] - 0s 746us/step\n",
      " **** Master of the Universe ***** \n",
      "   Cantidad de NaN en cat1:  0\n",
      " ********************************* \n",
      " **** process_and_train_model()  ***** \n",
      "   Cantidad de NaN en cat1:  0\n",
      " ********************************* \n",
      "126/126 [==============================] - 0s 780us/step\n",
      "126/126 [==============================] - 0s 797us/step\n",
      "126/126 [==============================] - 0s 1ms/step\n",
      "126/126 [==============================] - 0s 817us/step\n",
      "126/126 [==============================] - 0s 795us/step\n",
      "25/25 [==============================] - 0s 735us/step\n",
      " -----------------------------------------------\n",
      "  Verificando valores infinitos\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "\n",
      "\n",
      "-----------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------\n",
      "    >>>>>>>>>>>>       Total Forecast Error: 25.26%     <<<<<<<<<<<<<<<<<<\n",
      "-----------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Predicciones ajustadas guardadas en ../666_Kaggle/Entregas/20240713-0844-LSTM_v8v4_feb_tfe2_0.2798.csv\n",
      "Métricas y parámetros guardados en ../666_Kaggle/Entregas/20240713-0844-LSTM_v8v4_feb_tfe2_0.2798.csv.metrics.json\n",
      "\n",
      "\n",
      "# -------------------------------------------------------------------------------------------------------------------\n",
      "# Tiempo de Ejecucion:\n",
      "#    Tiempo de inicio: 2024-07-13 08:15:25\n",
      "#    Tiempo de actual: 2024-07-13 08:44:14\n",
      "# \n",
      "#    Tiempo transcurrido: 1729.066246 segundos\n",
      "# \n",
      "# LSTM Parameters:\n",
      "#   seed=52, seq_length=3, epochs=50, batch_size=64, learning_rate=0.0001, patience=10, verbose=0, standard_scaler=0 \n",
      "# -------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      " **** process_and_train_model()  ***** \n",
      "   Cantidad de NaN en cat1:  0\n",
      " ********************************* \n",
      "135/135 [==============================] - 0s 589us/step\n",
      "135/135 [==============================] - 0s 837us/step\n",
      "135/135 [==============================] - 0s 599us/step\n",
      "135/135 [==============================] - 0s 613us/step\n",
      "135/135 [==============================] - 0s 646us/step\n",
      "25/25 [==============================] - 0s 544us/step\n",
      " **** Master of the Universe ***** \n",
      "   Cantidad de NaN en cat1:  0\n",
      " ********************************* \n",
      " **** process_and_train_model()  ***** \n",
      "   Cantidad de NaN en cat1:  0\n",
      " ********************************* \n",
      "139/139 [==============================] - 0s 673us/step\n",
      "139/139 [==============================] - 0s 615us/step\n",
      "139/139 [==============================] - 0s 619us/step\n",
      "139/139 [==============================] - 0s 607us/step\n",
      "139/139 [==============================] - 0s 609us/step\n",
      "25/25 [==============================] - 0s 590us/step\n",
      " -----------------------------------------------\n",
      "  Verificando valores infinitos\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "\n",
      "\n",
      "-----------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------\n",
      "    >>>>>>>>>>>>       Total Forecast Error: 25.46%     <<<<<<<<<<<<<<<<<<\n",
      "-----------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Predicciones ajustadas guardadas en ../666_Kaggle/Entregas/20240713-0846-LSTM_v8v4_feb_tfe2_0.278.csv\n",
      "Métricas y parámetros guardados en ../666_Kaggle/Entregas/20240713-0846-LSTM_v8v4_feb_tfe2_0.278.csv.metrics.json\n",
      "\n",
      "\n",
      "# -------------------------------------------------------------------------------------------------------------------\n",
      "# Tiempo de Ejecucion:\n",
      "#    Tiempo de inicio: 2024-07-13 08:15:25\n",
      "#    Tiempo de actual: 2024-07-13 08:46:39\n",
      "# \n",
      "#    Tiempo transcurrido: 1874.698586 segundos\n",
      "# \n",
      "# LSTM Parameters:\n",
      "#   seed=52, seq_length=6, epochs=50, batch_size=64, learning_rate=0.0001, patience=10, verbose=0, standard_scaler=0 \n",
      "# -------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      " **** process_and_train_model()  ***** \n",
      "   Cantidad de NaN en cat1:  0\n",
      " ********************************* \n",
      "122/122 [==============================] - 0s 1ms/step\n",
      "122/122 [==============================] - 0s 815us/step\n",
      "122/122 [==============================] - 0s 821us/step\n",
      "122/122 [==============================] - 0s 812us/step\n",
      "122/122 [==============================] - 0s 803us/step\n",
      "25/25 [==============================] - 0s 777us/step\n",
      " **** Master of the Universe ***** \n",
      "   Cantidad de NaN en cat1:  0\n",
      " ********************************* \n",
      " **** process_and_train_model()  ***** \n",
      "   Cantidad de NaN en cat1:  0\n",
      " ********************************* \n",
      "126/126 [==============================] - 0s 1ms/step\n",
      "126/126 [==============================] - 0s 799us/step\n",
      "126/126 [==============================] - 0s 824us/step\n",
      "126/126 [==============================] - 0s 1ms/step\n",
      "126/126 [==============================] - 0s 830us/step\n",
      "25/25 [==============================] - 0s 785us/step\n",
      " -----------------------------------------------\n",
      "  Verificando valores infinitos\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "\n",
      "\n",
      "-----------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------\n",
      "    >>>>>>>>>>>>       Total Forecast Error: 25.97%     <<<<<<<<<<<<<<<<<<\n",
      "-----------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Predicciones ajustadas guardadas en ../666_Kaggle/Entregas/20240713-0849-LSTM_v8v4_feb_tfe2_0.2867.csv\n",
      "Métricas y parámetros guardados en ../666_Kaggle/Entregas/20240713-0849-LSTM_v8v4_feb_tfe2_0.2867.csv.metrics.json\n",
      "\n",
      "\n",
      "# -------------------------------------------------------------------------------------------------------------------\n",
      "# Tiempo de Ejecucion:\n",
      "#    Tiempo de inicio: 2024-07-13 08:15:25\n",
      "#    Tiempo de actual: 2024-07-13 08:49:44\n",
      "# \n",
      "#    Tiempo transcurrido: 2059.534509 segundos\n",
      "# \n",
      "# LSTM Parameters:\n",
      "#   seed=52, seq_length=3, epochs=20, batch_size=32, learning_rate=0.0001, patience=10, verbose=0, standard_scaler=0 \n",
      "# -------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      " **** process_and_train_model()  ***** \n",
      "   Cantidad de NaN en cat1:  0\n",
      " ********************************* \n",
      "135/135 [==============================] - 0s 632us/step\n",
      "135/135 [==============================] - 0s 604us/step\n",
      "135/135 [==============================] - 0s 620us/step\n",
      "135/135 [==============================] - 0s 596us/step\n",
      "135/135 [==============================] - 0s 621us/step\n",
      "25/25 [==============================] - 0s 614us/step\n",
      " **** Master of the Universe ***** \n",
      "   Cantidad de NaN en cat1:  0\n",
      " ********************************* \n",
      " **** process_and_train_model()  ***** \n",
      "   Cantidad de NaN en cat1:  0\n",
      " ********************************* \n",
      "139/139 [==============================] - 0s 587us/step\n",
      "139/139 [==============================] - 0s 593us/step\n",
      "139/139 [==============================] - 0s 594us/step\n",
      "139/139 [==============================] - 0s 607us/step\n",
      "139/139 [==============================] - 0s 632us/step\n",
      "25/25 [==============================] - 0s 580us/step\n",
      " -----------------------------------------------\n",
      "  Verificando valores infinitos\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "\n",
      "\n",
      "-----------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------\n",
      "    >>>>>>>>>>>>       Total Forecast Error: 26.06%     <<<<<<<<<<<<<<<<<<\n",
      "-----------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Predicciones ajustadas guardadas en ../666_Kaggle/Entregas/20240713-0852-LSTM_v8v4_feb_tfe2_0.2831.csv\n",
      "Métricas y parámetros guardados en ../666_Kaggle/Entregas/20240713-0852-LSTM_v8v4_feb_tfe2_0.2831.csv.metrics.json\n",
      "\n",
      "\n",
      "# -------------------------------------------------------------------------------------------------------------------\n",
      "# Tiempo de Ejecucion:\n",
      "#    Tiempo de inicio: 2024-07-13 08:15:25\n",
      "#    Tiempo de actual: 2024-07-13 08:52:19\n",
      "# \n",
      "#    Tiempo transcurrido: 2214.392654 segundos\n",
      "# \n",
      "# LSTM Parameters:\n",
      "#   seed=52, seq_length=6, epochs=20, batch_size=32, learning_rate=0.0001, patience=10, verbose=0, standard_scaler=0 \n",
      "# -------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      " **** process_and_train_model()  ***** \n",
      "   Cantidad de NaN en cat1:  0\n",
      " ********************************* \n",
      "122/122 [==============================] - 0s 785us/step\n",
      "122/122 [==============================] - 0s 841us/step\n",
      "122/122 [==============================] - 0s 796us/step\n",
      "122/122 [==============================] - 0s 1ms/step\n",
      "122/122 [==============================] - 0s 773us/step\n",
      "25/25 [==============================] - 0s 743us/step\n",
      " **** Master of the Universe ***** \n",
      "   Cantidad de NaN en cat1:  0\n",
      " ********************************* \n",
      " **** process_and_train_model()  ***** \n",
      "   Cantidad de NaN en cat1:  0\n",
      " ********************************* \n",
      "126/126 [==============================] - 0s 788us/step\n",
      "126/126 [==============================] - 0s 1ms/step\n",
      "126/126 [==============================] - 0s 799us/step\n",
      "126/126 [==============================] - 0s 802us/step\n",
      "126/126 [==============================] - 0s 804us/step\n",
      "25/25 [==============================] - 0s 2ms/step\n",
      " -----------------------------------------------\n",
      "  Verificando valores infinitos\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "\n",
      "\n",
      "-----------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------\n",
      "    >>>>>>>>>>>>       Total Forecast Error: 27.11%     <<<<<<<<<<<<<<<<<<\n",
      "-----------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Predicciones ajustadas guardadas en ../666_Kaggle/Entregas/20240713-0855-LSTM_v8v4_feb_tfe2_0.2991.csv\n",
      "Métricas y parámetros guardados en ../666_Kaggle/Entregas/20240713-0855-LSTM_v8v4_feb_tfe2_0.2991.csv.metrics.json\n",
      "\n",
      "\n",
      "# -------------------------------------------------------------------------------------------------------------------\n",
      "# Tiempo de Ejecucion:\n",
      "#    Tiempo de inicio: 2024-07-13 08:15:25\n",
      "#    Tiempo de actual: 2024-07-13 08:55:40\n",
      "# \n",
      "#    Tiempo transcurrido: 2414.904774 segundos\n",
      "# \n",
      "# LSTM Parameters:\n",
      "#   seed=52, seq_length=3, epochs=20, batch_size=64, learning_rate=0.0001, patience=10, verbose=0, standard_scaler=0 \n",
      "# -------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      " **** process_and_train_model()  ***** \n",
      "   Cantidad de NaN en cat1:  0\n",
      " ********************************* \n",
      "135/135 [==============================] - 0s 584us/step\n",
      "135/135 [==============================] - 0s 587us/step\n",
      "135/135 [==============================] - 0s 585us/step\n",
      "135/135 [==============================] - 0s 822us/step\n",
      "135/135 [==============================] - 0s 586us/step\n",
      "25/25 [==============================] - 0s 578us/step\n",
      " **** Master of the Universe ***** \n",
      "   Cantidad de NaN en cat1:  0\n",
      " ********************************* \n",
      " **** process_and_train_model()  ***** \n",
      "   Cantidad de NaN en cat1:  0\n",
      " ********************************* \n",
      "139/139 [==============================] - 0s 580us/step\n",
      "139/139 [==============================] - 0s 585us/step\n",
      "139/139 [==============================] - 0s 602us/step\n",
      "139/139 [==============================] - 0s 590us/step\n",
      "139/139 [==============================] - 0s 594us/step\n",
      "25/25 [==============================] - 0s 588us/step\n",
      " -----------------------------------------------\n",
      "  Verificando valores infinitos\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "\n",
      "\n",
      "-----------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------\n",
      "    >>>>>>>>>>>>       Total Forecast Error: 29.50%     <<<<<<<<<<<<<<<<<<\n",
      "-----------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Predicciones ajustadas guardadas en ../666_Kaggle/Entregas/20240713-0857-LSTM_v8v4_feb_tfe2_0.3026.csv\n",
      "Métricas y parámetros guardados en ../666_Kaggle/Entregas/20240713-0857-LSTM_v8v4_feb_tfe2_0.3026.csv.metrics.json\n",
      "\n",
      "\n",
      "# -------------------------------------------------------------------------------------------------------------------\n",
      "# Tiempo de Ejecucion:\n",
      "#    Tiempo de inicio: 2024-07-13 08:15:25\n",
      "#    Tiempo de actual: 2024-07-13 08:57:16\n",
      "# \n",
      "#    Tiempo transcurrido: 2511.585002 segundos\n",
      "# \n",
      "# LSTM Parameters:\n",
      "#   seed=52, seq_length=6, epochs=20, batch_size=64, learning_rate=0.0001, patience=10, verbose=0, standard_scaler=0 \n",
      "# -------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      " **** process_and_train_model()  ***** \n",
      "   Cantidad de NaN en cat1:  0\n",
      " ********************************* \n",
      "122/122 [==============================] - 0s 1ms/step\n",
      "122/122 [==============================] - 0s 799us/step\n",
      "122/122 [==============================] - 0s 768us/step\n",
      "122/122 [==============================] - 0s 790us/step\n",
      "122/122 [==============================] - 0s 1ms/step\n",
      "25/25 [==============================] - 0s 765us/step\n",
      " **** Master of the Universe ***** \n",
      "   Cantidad de NaN en cat1:  0\n",
      " ********************************* \n",
      " **** process_and_train_model()  ***** \n",
      "   Cantidad de NaN en cat1:  0\n",
      " ********************************* \n",
      "126/126 [==============================] - 0s 783us/step\n",
      "126/126 [==============================] - 0s 794us/step\n",
      "126/126 [==============================] - 0s 1ms/step\n",
      "126/126 [==============================] - 0s 793us/step\n",
      "126/126 [==============================] - 0s 788us/step\n",
      "25/25 [==============================] - 0s 784us/step\n",
      " -----------------------------------------------\n",
      "  Verificando valores infinitos\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "\n",
      "\n",
      "-----------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------\n",
      "    >>>>>>>>>>>>       Total Forecast Error: 29.38%     <<<<<<<<<<<<<<<<<<\n",
      "-----------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Predicciones ajustadas guardadas en ../666_Kaggle/Entregas/20240713-0859-LSTM_v8v4_feb_tfe2_0.3213.csv\n",
      "Métricas y parámetros guardados en ../666_Kaggle/Entregas/20240713-0859-LSTM_v8v4_feb_tfe2_0.3213.csv.metrics.json\n",
      "\n",
      "\n",
      "# -------------------------------------------------------------------------------------------------------------------\n",
      "# Tiempo de Ejecucion:\n",
      "#    Tiempo de inicio: 2024-07-13 08:15:25\n",
      "#    Tiempo de actual: 2024-07-13 08:57:16\n",
      "# \n",
      "#    Tiempo transcurrido: 2511.585002 segundos\n",
      "# \n",
      "# LSTM Parameters:\n",
      "#   seed=52, seq_length=6, epochs=20, batch_size=64, learning_rate=0.0001, patience=10, verbose=0, standard_scaler=0 \n",
      "# -------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "# Fijar la semilla para reproducibilidad\n",
    "#SEED = 52\n",
    "#np.random.seed(SEED)\n",
    "#tf.random.set_seed(SEED)\n",
    "#random.seed(SEED)\n",
    "\n",
    "# Definir listas de valores para los parámetros que se van a probar\n",
    "#seq_lengths = [6, 12]\n",
    "#epochs_list = [50, 150]\n",
    "#batch_sizes = [32, 48, 64]\n",
    "#patience_list = [10, 20]\n",
    "##learning_rates = [0.0001, 0.0005, 0.001, 0.01]\n",
    "#verbose_list = [0]\n",
    "#standard_scalerS = [0] # [0, 1]\n",
    "\n",
    "# Definir la variable para controlar si se incluyen las predicciones futuras o no\n",
    "future_prediction = True  # True para predecir febrero 2020, False para entrenar solo hasta octubre 2019\n",
    "\n",
    "SEEDs = [52]\n",
    "seq_lengths = [3,6]\n",
    "epochs_list = [50,20]\n",
    "batch_sizes = [32,64]\n",
    "learning_rates = [0.0001]\n",
    "patience_list = [10]\n",
    "verbose_list = [0]\n",
    "standard_scalerS = [1,0] # [0, 1]\n",
    "\n",
    "\n",
    "\n",
    "# Calcular el número total de combinaciones:\n",
    "total_combinations = len(SEEDs) * len(seq_lengths) * len(epochs_list) * len(batch_sizes) * \\\n",
    "                     len(learning_rates) * len(patience_list) * len(verbose_list) * len(standard_scalerS)\n",
    "\n",
    "print(\"Total de combinaciones:\", total_combinations)\n",
    "\n",
    "\n",
    "# Registrar el tiempo de inicio al inicio del script\n",
    "inicio, inicio_str = registrar_tiempo()\n",
    "\n",
    "\n",
    "# Iterar sobre todas las combinaciones de valores de parámetros\n",
    "for seed in SEEDs:\n",
    "    # Fijar la semilla para reproducibilidad    \n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    random.seed(seed)\n",
    "    for standard_scaler in standard_scalerS:    \n",
    "        for epochs in epochs_list:\n",
    "            for batch_size in batch_sizes:\n",
    "                for learning_rate in learning_rates:\n",
    "                    for patience in patience_list:\n",
    "                        for verbose in verbose_list:\n",
    "                            for seq_length in seq_lengths:                                                            \n",
    "                                # Cargar los datos\n",
    "                                ventas_LTSM_path = '../66_Datos/sell-z-780-all-LTSM.csv'\n",
    "                                df_ventas = pd.read_csv(ventas_LTSM_path)\n",
    "\n",
    "                                # Convertir la columna 'periodo' a tipo datetime\n",
    "                                df_ventas['periodo'] = pd.to_datetime(df_ventas['periodo'], format='%Y-%m-%d')\n",
    "                                \n",
    "                                # Filtrar los datos si future_prediction es False hasta octubre 2019\n",
    "                                if not future_prediction:\n",
    "                                    df_ventas = df_ventas[df_ventas['periodo'] <= '2019-10-01']\n",
    "                                    \n",
    "                                # Definir los parámetros utilizados\n",
    "                                parameters = {\n",
    "                                    \"seq_length\": seq_length,\n",
    "                                    \"epochs\": epochs,\n",
    "                                    \"batch_size\": batch_size,\n",
    "                                    \"learning_rate\": learning_rate,\n",
    "                                    \"patience\": patience,\n",
    "                                    \"verbose\": verbose,\n",
    "                                    \"seed\": seed,\n",
    "                                    \"standard_scaler\": standard_scaler\n",
    "                                }\n",
    "                                # Registrar el tiempo de finalización al final del script\n",
    "                                fin, fin_str = registrar_tiempo()\n",
    "                                # Calcular el tiempo transcurrido\n",
    "                                tiempo_transcurrido = calcular_tiempo_transcurrido(inicio, fin)\n",
    "\n",
    "                                print('\\n')\n",
    "                                print('# -------------------------------------------------------------------------------------------------------------------')\n",
    "                                print('# Tiempo de Ejecucion:')\n",
    "                                print(f\"#    Tiempo de inicio: {inicio_str}\")\n",
    "                                print(f\"#    Tiempo de actual: {fin_str}\")\n",
    "                                print('# ') \n",
    "                                print(f\"#    Tiempo transcurrido: {tiempo_transcurrido} segundos\")             \n",
    "                                print('# ')\n",
    "                                print('# LSTM Parameters:')\n",
    "                                print(f'#   seed={seed}, seq_length={seq_length}, epochs={epochs}, batch_size={batch_size}, learning_rate={learning_rate}, patience={patience}, verbose={verbose}, standard_scaler={standard_scaler} ')\n",
    "                                print('# -------------------------------------------------------------------------------------------------------------------')\n",
    "                                print('\\n')\n",
    "                                \n",
    "                                # Llamar a la función principal con los parámetros\n",
    "                                df_ventas2, weights_dict = master_of_the_universe()\n",
    "\n",
    "                                # Registrar el tiempo de finalización al final del script\n",
    "                                #fin, fin_str = registrar_tiempo()\n",
    "\n",
    "                                # Calcular el tiempo transcurrido\n",
    "                                #tiempo_transcurrido = calcular_tiempo_transcurrido(inicio, fin)\n",
    "\n",
    "                                #print(f\"Tiempo de inicio: {inicio_str}\")\n",
    "                                #print(f\"Tiempo de finalización: {fin_str}\")\n",
    "                                #print(f\"Tiempo transcurrido: {tiempo_transcurrido} segundos\")\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "print('# -------------------------------------------------------------------------------------------------------------------')\n",
    "print('# Tiempo de Ejecucion:')\n",
    "print(f\"#    Tiempo de inicio: {inicio_str}\")\n",
    "print(f\"#    Tiempo de actual: {fin_str}\")\n",
    "print('# ') \n",
    "print(f\"#    Tiempo transcurrido: {tiempo_transcurrido} segundos\")             \n",
    "print('# ')\n",
    "print('# LSTM Parameters:')\n",
    "print(f'#   seed={seed}, seq_length={seq_length}, epochs={epochs}, batch_size={batch_size}, learning_rate={learning_rate}, patience={patience}, verbose={verbose}, standard_scaler={standard_scaler} ')\n",
    "print('# -------------------------------------------------------------------------------------------------------------------')\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74f1251b-3580-412c-a85a-ae08d3170c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#weights_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d5c6737-0cab-4274-a6f4-3deb1fbb3ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>periodo</th>\n",
       "      <th>plan_precios_cuidados</th>\n",
       "      <th>cust_request_qty</th>\n",
       "      <th>cust_request_tn</th>\n",
       "      <th>tn</th>\n",
       "      <th>cant_periodos</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>brand</th>\n",
       "      <th>sku_size</th>\n",
       "      <th>descripcion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20001</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>479.0</td>\n",
       "      <td>937.72717</td>\n",
       "      <td>934.772220</td>\n",
       "      <td>36.0</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>ARIEL</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>genoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20001</td>\n",
       "      <td>2017-02-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>432.0</td>\n",
       "      <td>833.72187</td>\n",
       "      <td>798.016200</td>\n",
       "      <td>36.0</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>ARIEL</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>genoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20001</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>509.0</td>\n",
       "      <td>1330.74697</td>\n",
       "      <td>1303.357710</td>\n",
       "      <td>36.0</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>ARIEL</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>genoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20001</td>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>1132.94430</td>\n",
       "      <td>1069.961300</td>\n",
       "      <td>36.0</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>ARIEL</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>genoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20001</td>\n",
       "      <td>2017-05-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>701.0</td>\n",
       "      <td>1550.68936</td>\n",
       "      <td>1502.201320</td>\n",
       "      <td>36.0</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>ARIEL</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>genoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27295</th>\n",
       "      <td>20962</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.104172</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27296</th>\n",
       "      <td>20975</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.715978</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27297</th>\n",
       "      <td>20995</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.298939</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27298</th>\n",
       "      <td>21087</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.513250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27299</th>\n",
       "      <td>21214</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.233837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27300 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       product_id     periodo  plan_precios_cuidados  cust_request_qty  \\\n",
       "0           20001  2017-01-01                    0.0             479.0   \n",
       "1           20001  2017-02-01                    0.0             432.0   \n",
       "2           20001  2017-03-01                    0.0             509.0   \n",
       "3           20001  2017-04-01                    0.0             279.0   \n",
       "4           20001  2017-05-01                    0.0             701.0   \n",
       "...           ...         ...                    ...               ...   \n",
       "27295       20962  2019-11-01                    NaN               NaN   \n",
       "27296       20975  2019-11-01                    NaN               NaN   \n",
       "27297       20995  2019-11-01                    NaN               NaN   \n",
       "27298       21087  2019-11-01                    NaN               NaN   \n",
       "27299       21214  2019-11-01                    NaN               NaN   \n",
       "\n",
       "       cust_request_tn           tn  cant_periodos   cat1         cat2  \\\n",
       "0            937.72717   934.772220           36.0     HC  ROPA LAVADO   \n",
       "1            833.72187   798.016200           36.0     HC  ROPA LAVADO   \n",
       "2           1330.74697  1303.357710           36.0     HC  ROPA LAVADO   \n",
       "3           1132.94430  1069.961300           36.0     HC  ROPA LAVADO   \n",
       "4           1550.68936  1502.201320           36.0     HC  ROPA LAVADO   \n",
       "...                ...          ...            ...    ...          ...   \n",
       "27295              NaN     6.104172            NaN  FOODS          NaN   \n",
       "27296              NaN     5.715978            NaN  FOODS          NaN   \n",
       "27297              NaN     5.298939            NaN  FOODS          NaN   \n",
       "27298              NaN     0.513250            NaN     PC          NaN   \n",
       "27299              NaN     0.233837            NaN     PC          NaN   \n",
       "\n",
       "          cat3  brand  sku_size descripcion  \n",
       "0      Liquido  ARIEL    3000.0      genoma  \n",
       "1      Liquido  ARIEL    3000.0      genoma  \n",
       "2      Liquido  ARIEL    3000.0      genoma  \n",
       "3      Liquido  ARIEL    3000.0      genoma  \n",
       "4      Liquido  ARIEL    3000.0      genoma  \n",
       "...        ...    ...       ...         ...  \n",
       "27295      NaN    NaN       NaN         NaN  \n",
       "27296      NaN    NaN       NaN         NaN  \n",
       "27297      NaN    NaN       NaN         NaN  \n",
       "27298      NaN    NaN       NaN         NaN  \n",
       "27299      NaN    NaN       NaN         NaN  \n",
       "\n",
       "[27300 rows x 13 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ventas2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b10bb67b-b5c0-4f8e-bd05-046cb3c71484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27300 entries, 0 to 27299\n",
      "Data columns (total 13 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   product_id             27300 non-null  int64  \n",
      " 1   periodo                27300 non-null  object \n",
      " 2   plan_precios_cuidados  26520 non-null  float64\n",
      " 3   cust_request_qty       26520 non-null  float64\n",
      " 4   cust_request_tn        26520 non-null  float64\n",
      " 5   tn                     27300 non-null  float64\n",
      " 6   cant_periodos          26520 non-null  float64\n",
      " 7   cat1                   27300 non-null  object \n",
      " 8   cat2                   26520 non-null  object \n",
      " 9   cat3                   26520 non-null  object \n",
      " 10  brand                  26520 non-null  object \n",
      " 11  sku_size               26520 non-null  float64\n",
      " 12  descripcion            26520 non-null  object \n",
      "dtypes: float64(6), int64(1), object(6)\n",
      "memory usage: 2.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df_ventas2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f0ab0f0-9cc2-46fd-af7b-c6359e99973b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ********************************* \n",
      "   Cantidad de NaN en cat1:  0\n",
      " ********************************* \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Supongamos que df_referencia es tu DataFrame de referencia con product_id y cat1 correctos\n",
    "# df_referencia = pd.DataFrame({'product_id': [1, 2, 3], 'cat1': ['A', 'B', 'C']})\n",
    "\n",
    "# Crear el DataFrame de referencia desde df_ventas2\n",
    "df_referencia = df_ventas2[['product_id', 'cat1']].dropna().drop_duplicates()\n",
    "\n",
    "# Crear un diccionario de mapeo de product_id a cat1\n",
    "cat1_mapping = df_referencia.set_index('product_id')['cat1'].to_dict()\n",
    "\n",
    "# Completar los valores NaN en cat1 en df_ventas2 usando el mapeo\n",
    "df_ventas2['cat1'] = df_ventas2['cat1'].fillna(df_ventas2['product_id'].map(cat1_mapping))\n",
    "\n",
    "# Verificar que no hay valores NaN en cat1\n",
    "print(\" ********************************* \")\n",
    "print(\"   Cantidad de NaN en cat1: \", df_ventas2['cat1'].isna().sum())\n",
    "print(\" ********************************* \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "165e98e1-5fe0-4923-9408-290437c8fab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>periodo</th>\n",
       "      <th>plan_precios_cuidados</th>\n",
       "      <th>cust_request_qty</th>\n",
       "      <th>cust_request_tn</th>\n",
       "      <th>tn</th>\n",
       "      <th>cant_periodos</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>brand</th>\n",
       "      <th>sku_size</th>\n",
       "      <th>descripcion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20001</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>479.0</td>\n",
       "      <td>937.72717</td>\n",
       "      <td>934.772220</td>\n",
       "      <td>36.0</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>ARIEL</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>genoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20001</td>\n",
       "      <td>2017-02-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>432.0</td>\n",
       "      <td>833.72187</td>\n",
       "      <td>798.016200</td>\n",
       "      <td>36.0</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>ARIEL</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>genoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20001</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>509.0</td>\n",
       "      <td>1330.74697</td>\n",
       "      <td>1303.357710</td>\n",
       "      <td>36.0</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>ARIEL</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>genoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20001</td>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>1132.94430</td>\n",
       "      <td>1069.961300</td>\n",
       "      <td>36.0</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>ARIEL</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>genoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20001</td>\n",
       "      <td>2017-05-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>701.0</td>\n",
       "      <td>1550.68936</td>\n",
       "      <td>1502.201320</td>\n",
       "      <td>36.0</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>Liquido</td>\n",
       "      <td>ARIEL</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>genoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27295</th>\n",
       "      <td>20962</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.104172</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27296</th>\n",
       "      <td>20975</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.715978</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27297</th>\n",
       "      <td>20995</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.298939</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27298</th>\n",
       "      <td>21087</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.513250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27299</th>\n",
       "      <td>21214</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.233837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27300 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       product_id     periodo  plan_precios_cuidados  cust_request_qty  \\\n",
       "0           20001  2017-01-01                    0.0             479.0   \n",
       "1           20001  2017-02-01                    0.0             432.0   \n",
       "2           20001  2017-03-01                    0.0             509.0   \n",
       "3           20001  2017-04-01                    0.0             279.0   \n",
       "4           20001  2017-05-01                    0.0             701.0   \n",
       "...           ...         ...                    ...               ...   \n",
       "27295       20962  2019-11-01                    NaN               NaN   \n",
       "27296       20975  2019-11-01                    NaN               NaN   \n",
       "27297       20995  2019-11-01                    NaN               NaN   \n",
       "27298       21087  2019-11-01                    NaN               NaN   \n",
       "27299       21214  2019-11-01                    NaN               NaN   \n",
       "\n",
       "       cust_request_tn           tn  cant_periodos   cat1         cat2  \\\n",
       "0            937.72717   934.772220           36.0     HC  ROPA LAVADO   \n",
       "1            833.72187   798.016200           36.0     HC  ROPA LAVADO   \n",
       "2           1330.74697  1303.357710           36.0     HC  ROPA LAVADO   \n",
       "3           1132.94430  1069.961300           36.0     HC  ROPA LAVADO   \n",
       "4           1550.68936  1502.201320           36.0     HC  ROPA LAVADO   \n",
       "...                ...          ...            ...    ...          ...   \n",
       "27295              NaN     6.104172            NaN  FOODS          NaN   \n",
       "27296              NaN     5.715978            NaN  FOODS          NaN   \n",
       "27297              NaN     5.298939            NaN  FOODS          NaN   \n",
       "27298              NaN     0.513250            NaN     PC          NaN   \n",
       "27299              NaN     0.233837            NaN     PC          NaN   \n",
       "\n",
       "          cat3  brand  sku_size descripcion  \n",
       "0      Liquido  ARIEL    3000.0      genoma  \n",
       "1      Liquido  ARIEL    3000.0      genoma  \n",
       "2      Liquido  ARIEL    3000.0      genoma  \n",
       "3      Liquido  ARIEL    3000.0      genoma  \n",
       "4      Liquido  ARIEL    3000.0      genoma  \n",
       "...        ...    ...       ...         ...  \n",
       "27295      NaN    NaN       NaN         NaN  \n",
       "27296      NaN    NaN       NaN         NaN  \n",
       "27297      NaN    NaN       NaN         NaN  \n",
       "27298      NaN    NaN       NaN         NaN  \n",
       "27299      NaN    NaN       NaN         NaN  \n",
       "\n",
       "[27300 rows x 13 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ventas2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f3bddd1-e1fb-4a0c-8605-0ab3c1f3cdb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>periodo</th>\n",
       "      <th>plan_precios_cuidados</th>\n",
       "      <th>cust_request_qty</th>\n",
       "      <th>cust_request_tn</th>\n",
       "      <th>tn</th>\n",
       "      <th>cant_periodos</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>brand</th>\n",
       "      <th>sku_size</th>\n",
       "      <th>descripcion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26486</th>\n",
       "      <td>21214</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>PC</td>\n",
       "      <td>DEOS</td>\n",
       "      <td>RollOn</td>\n",
       "      <td>NIVEA</td>\n",
       "      <td>50.0</td>\n",
       "      <td>Aroma 14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26487</th>\n",
       "      <td>21214</td>\n",
       "      <td>2017-02-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>PC</td>\n",
       "      <td>DEOS</td>\n",
       "      <td>RollOn</td>\n",
       "      <td>NIVEA</td>\n",
       "      <td>50.0</td>\n",
       "      <td>Aroma 14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26488</th>\n",
       "      <td>21214</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>PC</td>\n",
       "      <td>DEOS</td>\n",
       "      <td>RollOn</td>\n",
       "      <td>NIVEA</td>\n",
       "      <td>50.0</td>\n",
       "      <td>Aroma 14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26489</th>\n",
       "      <td>21214</td>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>PC</td>\n",
       "      <td>DEOS</td>\n",
       "      <td>RollOn</td>\n",
       "      <td>NIVEA</td>\n",
       "      <td>50.0</td>\n",
       "      <td>Aroma 14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26490</th>\n",
       "      <td>21214</td>\n",
       "      <td>2017-05-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>PC</td>\n",
       "      <td>DEOS</td>\n",
       "      <td>RollOn</td>\n",
       "      <td>NIVEA</td>\n",
       "      <td>50.0</td>\n",
       "      <td>Aroma 14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26491</th>\n",
       "      <td>21214</td>\n",
       "      <td>2017-06-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>PC</td>\n",
       "      <td>DEOS</td>\n",
       "      <td>RollOn</td>\n",
       "      <td>NIVEA</td>\n",
       "      <td>50.0</td>\n",
       "      <td>Aroma 14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26492</th>\n",
       "      <td>21214</td>\n",
       "      <td>2017-07-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>PC</td>\n",
       "      <td>DEOS</td>\n",
       "      <td>RollOn</td>\n",
       "      <td>NIVEA</td>\n",
       "      <td>50.0</td>\n",
       "      <td>Aroma 14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26493</th>\n",
       "      <td>21214</td>\n",
       "      <td>2017-08-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>PC</td>\n",
       "      <td>DEOS</td>\n",
       "      <td>RollOn</td>\n",
       "      <td>NIVEA</td>\n",
       "      <td>50.0</td>\n",
       "      <td>Aroma 14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26494</th>\n",
       "      <td>21214</td>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>PC</td>\n",
       "      <td>DEOS</td>\n",
       "      <td>RollOn</td>\n",
       "      <td>NIVEA</td>\n",
       "      <td>50.0</td>\n",
       "      <td>Aroma 14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26495</th>\n",
       "      <td>21214</td>\n",
       "      <td>2017-10-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>PC</td>\n",
       "      <td>DEOS</td>\n",
       "      <td>RollOn</td>\n",
       "      <td>NIVEA</td>\n",
       "      <td>50.0</td>\n",
       "      <td>Aroma 14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26496</th>\n",
       "      <td>21214</td>\n",
       "      <td>2017-11-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>PC</td>\n",
       "      <td>DEOS</td>\n",
       "      <td>RollOn</td>\n",
       "      <td>NIVEA</td>\n",
       "      <td>50.0</td>\n",
       "      <td>Aroma 14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26497</th>\n",
       "      <td>21214</td>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>PC</td>\n",
       "      <td>DEOS</td>\n",
       "      <td>RollOn</td>\n",
       "      <td>NIVEA</td>\n",
       "      <td>50.0</td>\n",
       "      <td>Aroma 14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26498</th>\n",
       "      <td>21214</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>PC</td>\n",
       "      <td>DEOS</td>\n",
       "      <td>RollOn</td>\n",
       "      <td>NIVEA</td>\n",
       "      <td>50.0</td>\n",
       "      <td>Aroma 14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26499</th>\n",
       "      <td>21214</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>PC</td>\n",
       "      <td>DEOS</td>\n",
       "      <td>RollOn</td>\n",
       "      <td>NIVEA</td>\n",
       "      <td>50.0</td>\n",
       "      <td>Aroma 14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26500</th>\n",
       "      <td>21214</td>\n",
       "      <td>2018-03-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>PC</td>\n",
       "      <td>DEOS</td>\n",
       "      <td>RollOn</td>\n",
       "      <td>NIVEA</td>\n",
       "      <td>50.0</td>\n",
       "      <td>Aroma 14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26501</th>\n",
       "      <td>21214</td>\n",
       "      <td>2018-04-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>PC</td>\n",
       "      <td>DEOS</td>\n",
       "      <td>RollOn</td>\n",
       "      <td>NIVEA</td>\n",
       "      <td>50.0</td>\n",
       "      <td>Aroma 14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26502</th>\n",
       "      <td>21214</td>\n",
       "      <td>2018-05-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>PC</td>\n",
       "      <td>DEOS</td>\n",
       "      <td>RollOn</td>\n",
       "      <td>NIVEA</td>\n",
       "      <td>50.0</td>\n",
       "      <td>Aroma 14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26503</th>\n",
       "      <td>21214</td>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>PC</td>\n",
       "      <td>DEOS</td>\n",
       "      <td>RollOn</td>\n",
       "      <td>NIVEA</td>\n",
       "      <td>50.0</td>\n",
       "      <td>Aroma 14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26504</th>\n",
       "      <td>21214</td>\n",
       "      <td>2018-07-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>PC</td>\n",
       "      <td>DEOS</td>\n",
       "      <td>RollOn</td>\n",
       "      <td>NIVEA</td>\n",
       "      <td>50.0</td>\n",
       "      <td>Aroma 14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26505</th>\n",
       "      <td>21214</td>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>PC</td>\n",
       "      <td>DEOS</td>\n",
       "      <td>RollOn</td>\n",
       "      <td>NIVEA</td>\n",
       "      <td>50.0</td>\n",
       "      <td>Aroma 14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26506</th>\n",
       "      <td>21214</td>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>PC</td>\n",
       "      <td>DEOS</td>\n",
       "      <td>RollOn</td>\n",
       "      <td>NIVEA</td>\n",
       "      <td>50.0</td>\n",
       "      <td>Aroma 14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26507</th>\n",
       "      <td>21214</td>\n",
       "      <td>2018-10-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>PC</td>\n",
       "      <td>DEOS</td>\n",
       "      <td>RollOn</td>\n",
       "      <td>NIVEA</td>\n",
       "      <td>50.0</td>\n",
       "      <td>Aroma 14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26508</th>\n",
       "      <td>21214</td>\n",
       "      <td>2018-11-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>PC</td>\n",
       "      <td>DEOS</td>\n",
       "      <td>RollOn</td>\n",
       "      <td>NIVEA</td>\n",
       "      <td>50.0</td>\n",
       "      <td>Aroma 14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26509</th>\n",
       "      <td>21214</td>\n",
       "      <td>2018-12-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>PC</td>\n",
       "      <td>DEOS</td>\n",
       "      <td>RollOn</td>\n",
       "      <td>NIVEA</td>\n",
       "      <td>50.0</td>\n",
       "      <td>Aroma 14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26510</th>\n",
       "      <td>21214</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>PC</td>\n",
       "      <td>DEOS</td>\n",
       "      <td>RollOn</td>\n",
       "      <td>NIVEA</td>\n",
       "      <td>50.0</td>\n",
       "      <td>Aroma 14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26511</th>\n",
       "      <td>21214</td>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>PC</td>\n",
       "      <td>DEOS</td>\n",
       "      <td>RollOn</td>\n",
       "      <td>NIVEA</td>\n",
       "      <td>50.0</td>\n",
       "      <td>Aroma 14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26512</th>\n",
       "      <td>21214</td>\n",
       "      <td>2019-03-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>PC</td>\n",
       "      <td>DEOS</td>\n",
       "      <td>RollOn</td>\n",
       "      <td>NIVEA</td>\n",
       "      <td>50.0</td>\n",
       "      <td>Aroma 14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26513</th>\n",
       "      <td>21214</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>PC</td>\n",
       "      <td>DEOS</td>\n",
       "      <td>RollOn</td>\n",
       "      <td>NIVEA</td>\n",
       "      <td>50.0</td>\n",
       "      <td>Aroma 14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26514</th>\n",
       "      <td>21214</td>\n",
       "      <td>2019-05-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>PC</td>\n",
       "      <td>DEOS</td>\n",
       "      <td>RollOn</td>\n",
       "      <td>NIVEA</td>\n",
       "      <td>50.0</td>\n",
       "      <td>Aroma 14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26515</th>\n",
       "      <td>21214</td>\n",
       "      <td>2019-06-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>PC</td>\n",
       "      <td>DEOS</td>\n",
       "      <td>RollOn</td>\n",
       "      <td>NIVEA</td>\n",
       "      <td>50.0</td>\n",
       "      <td>Aroma 14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26516</th>\n",
       "      <td>21214</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>PC</td>\n",
       "      <td>DEOS</td>\n",
       "      <td>RollOn</td>\n",
       "      <td>NIVEA</td>\n",
       "      <td>50.0</td>\n",
       "      <td>Aroma 14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26517</th>\n",
       "      <td>21214</td>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>PC</td>\n",
       "      <td>DEOS</td>\n",
       "      <td>RollOn</td>\n",
       "      <td>NIVEA</td>\n",
       "      <td>50.0</td>\n",
       "      <td>Aroma 14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26518</th>\n",
       "      <td>21214</td>\n",
       "      <td>2019-09-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.34250</td>\n",
       "      <td>0.342500</td>\n",
       "      <td>4.0</td>\n",
       "      <td>PC</td>\n",
       "      <td>DEOS</td>\n",
       "      <td>RollOn</td>\n",
       "      <td>NIVEA</td>\n",
       "      <td>50.0</td>\n",
       "      <td>Aroma 14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26519</th>\n",
       "      <td>21214</td>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.21735</td>\n",
       "      <td>0.217350</td>\n",
       "      <td>4.0</td>\n",
       "      <td>PC</td>\n",
       "      <td>DEOS</td>\n",
       "      <td>RollOn</td>\n",
       "      <td>NIVEA</td>\n",
       "      <td>50.0</td>\n",
       "      <td>Aroma 14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27299</th>\n",
       "      <td>21214</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.233837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       product_id     periodo  plan_precios_cuidados  cust_request_qty  \\\n",
       "26486       21214  2017-01-01                    0.0               0.0   \n",
       "26487       21214  2017-02-01                    0.0               0.0   \n",
       "26488       21214  2017-03-01                    0.0               0.0   \n",
       "26489       21214  2017-04-01                    0.0               0.0   \n",
       "26490       21214  2017-05-01                    0.0               0.0   \n",
       "26491       21214  2017-06-01                    0.0               0.0   \n",
       "26492       21214  2017-07-01                    0.0               0.0   \n",
       "26493       21214  2017-08-01                    0.0               0.0   \n",
       "26494       21214  2017-09-01                    0.0               0.0   \n",
       "26495       21214  2017-10-01                    0.0               0.0   \n",
       "26496       21214  2017-11-01                    0.0               0.0   \n",
       "26497       21214  2017-12-01                    0.0               0.0   \n",
       "26498       21214  2018-01-01                    0.0               0.0   \n",
       "26499       21214  2018-02-01                    0.0               0.0   \n",
       "26500       21214  2018-03-01                    0.0               0.0   \n",
       "26501       21214  2018-04-01                    0.0               0.0   \n",
       "26502       21214  2018-05-01                    0.0               0.0   \n",
       "26503       21214  2018-06-01                    0.0               0.0   \n",
       "26504       21214  2018-07-01                    0.0               0.0   \n",
       "26505       21214  2018-08-01                    0.0               0.0   \n",
       "26506       21214  2018-09-01                    0.0               0.0   \n",
       "26507       21214  2018-10-01                    0.0               0.0   \n",
       "26508       21214  2018-11-01                    0.0               0.0   \n",
       "26509       21214  2018-12-01                    0.0               0.0   \n",
       "26510       21214  2019-01-01                    0.0               0.0   \n",
       "26511       21214  2019-02-01                    0.0               0.0   \n",
       "26512       21214  2019-03-01                    0.0               0.0   \n",
       "26513       21214  2019-04-01                    0.0               0.0   \n",
       "26514       21214  2019-05-01                    0.0               0.0   \n",
       "26515       21214  2019-06-01                    0.0               0.0   \n",
       "26516       21214  2019-07-01                    0.0               0.0   \n",
       "26517       21214  2019-08-01                    0.0               0.0   \n",
       "26518       21214  2019-09-01                    0.0               3.0   \n",
       "26519       21214  2019-10-01                    0.0              46.0   \n",
       "27299       21214  2019-11-01                    NaN               NaN   \n",
       "\n",
       "       cust_request_tn        tn  cant_periodos cat1  cat2    cat3  brand  \\\n",
       "26486          0.00000  0.000000            4.0   PC  DEOS  RollOn  NIVEA   \n",
       "26487          0.00000  0.000000            4.0   PC  DEOS  RollOn  NIVEA   \n",
       "26488          0.00000  0.000000            4.0   PC  DEOS  RollOn  NIVEA   \n",
       "26489          0.00000  0.000000            4.0   PC  DEOS  RollOn  NIVEA   \n",
       "26490          0.00000  0.000000            4.0   PC  DEOS  RollOn  NIVEA   \n",
       "26491          0.00000  0.000000            4.0   PC  DEOS  RollOn  NIVEA   \n",
       "26492          0.00000  0.000000            4.0   PC  DEOS  RollOn  NIVEA   \n",
       "26493          0.00000  0.000000            4.0   PC  DEOS  RollOn  NIVEA   \n",
       "26494          0.00000  0.000000            4.0   PC  DEOS  RollOn  NIVEA   \n",
       "26495          0.00000  0.000000            4.0   PC  DEOS  RollOn  NIVEA   \n",
       "26496          0.00000  0.000000            4.0   PC  DEOS  RollOn  NIVEA   \n",
       "26497          0.00000  0.000000            4.0   PC  DEOS  RollOn  NIVEA   \n",
       "26498          0.00000  0.000000            4.0   PC  DEOS  RollOn  NIVEA   \n",
       "26499          0.00000  0.000000            4.0   PC  DEOS  RollOn  NIVEA   \n",
       "26500          0.00000  0.000000            4.0   PC  DEOS  RollOn  NIVEA   \n",
       "26501          0.00000  0.000000            4.0   PC  DEOS  RollOn  NIVEA   \n",
       "26502          0.00000  0.000000            4.0   PC  DEOS  RollOn  NIVEA   \n",
       "26503          0.00000  0.000000            4.0   PC  DEOS  RollOn  NIVEA   \n",
       "26504          0.00000  0.000000            4.0   PC  DEOS  RollOn  NIVEA   \n",
       "26505          0.00000  0.000000            4.0   PC  DEOS  RollOn  NIVEA   \n",
       "26506          0.00000  0.000000            4.0   PC  DEOS  RollOn  NIVEA   \n",
       "26507          0.00000  0.000000            4.0   PC  DEOS  RollOn  NIVEA   \n",
       "26508          0.00000  0.000000            4.0   PC  DEOS  RollOn  NIVEA   \n",
       "26509          0.00000  0.000000            4.0   PC  DEOS  RollOn  NIVEA   \n",
       "26510          0.00000  0.000000            4.0   PC  DEOS  RollOn  NIVEA   \n",
       "26511          0.00000  0.000000            4.0   PC  DEOS  RollOn  NIVEA   \n",
       "26512          0.00000  0.000000            4.0   PC  DEOS  RollOn  NIVEA   \n",
       "26513          0.00000  0.000000            4.0   PC  DEOS  RollOn  NIVEA   \n",
       "26514          0.00000  0.000000            4.0   PC  DEOS  RollOn  NIVEA   \n",
       "26515          0.00000  0.000000            4.0   PC  DEOS  RollOn  NIVEA   \n",
       "26516          0.00000  0.000000            4.0   PC  DEOS  RollOn  NIVEA   \n",
       "26517          0.00000  0.000000            4.0   PC  DEOS  RollOn  NIVEA   \n",
       "26518          0.34250  0.342500            4.0   PC  DEOS  RollOn  NIVEA   \n",
       "26519          0.21735  0.217350            4.0   PC  DEOS  RollOn  NIVEA   \n",
       "27299              NaN  0.233837            NaN   PC   NaN     NaN    NaN   \n",
       "\n",
       "       sku_size descripcion  \n",
       "26486      50.0    Aroma 14  \n",
       "26487      50.0    Aroma 14  \n",
       "26488      50.0    Aroma 14  \n",
       "26489      50.0    Aroma 14  \n",
       "26490      50.0    Aroma 14  \n",
       "26491      50.0    Aroma 14  \n",
       "26492      50.0    Aroma 14  \n",
       "26493      50.0    Aroma 14  \n",
       "26494      50.0    Aroma 14  \n",
       "26495      50.0    Aroma 14  \n",
       "26496      50.0    Aroma 14  \n",
       "26497      50.0    Aroma 14  \n",
       "26498      50.0    Aroma 14  \n",
       "26499      50.0    Aroma 14  \n",
       "26500      50.0    Aroma 14  \n",
       "26501      50.0    Aroma 14  \n",
       "26502      50.0    Aroma 14  \n",
       "26503      50.0    Aroma 14  \n",
       "26504      50.0    Aroma 14  \n",
       "26505      50.0    Aroma 14  \n",
       "26506      50.0    Aroma 14  \n",
       "26507      50.0    Aroma 14  \n",
       "26508      50.0    Aroma 14  \n",
       "26509      50.0    Aroma 14  \n",
       "26510      50.0    Aroma 14  \n",
       "26511      50.0    Aroma 14  \n",
       "26512      50.0    Aroma 14  \n",
       "26513      50.0    Aroma 14  \n",
       "26514      50.0    Aroma 14  \n",
       "26515      50.0    Aroma 14  \n",
       "26516      50.0    Aroma 14  \n",
       "26517      50.0    Aroma 14  \n",
       "26518      50.0    Aroma 14  \n",
       "26519      50.0    Aroma 14  \n",
       "27299       NaN         NaN  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ventas2.loc[df_ventas2.product_id == 21214]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17883a88-12c2-4239-abb8-f3cef4e49dcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
