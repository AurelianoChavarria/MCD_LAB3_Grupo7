








import pandas as pd

# Cargar los datos de ventas y productos a predecir
#sell-z-780-groupBy-Period-ProdId.csv
#ventas_file_path = '../66_Datos/sell-in.txt'
ventas_file_path = '../66_Datos/sell-z-780-groupBy-Period-ProdId.csv'
productos_file_path = '../66_Datos/productos_a_predecir.txt'
productos_descripcion = '../66_Datos/tb_productos_descripcion.txt'


# tb_productos_descripcion.txt es la ultima tabla (∫2024/06/15) que presento con las caracteristicas y categoria de cada producto
df_productos_descripcion = pd.read_csv(productos_descripcion, sep='\t')
df_productos_descripcion = df_productos_descripcion[['product_id', 'cat1', 'cat2', 'cat3', 'brand', 'sku_size', 'descripcion']]
df_productos_descripcion = df_productos_descripcion.reset_index(drop=True)
# Nota: no encuentro duplicados en productos_descripcion. De todas formas armo la sentencia de eliminarlos ya que pueden aparecer
#       futuras versiones del archivo
# Eliminar los duplicados en la columna 'product_id', manteniendo solo la primera aparición
df_productos_descripcion.drop_duplicates(subset='product_id', keep='first', inplace=True)

#df_ventas_orig = pd.read_csv(ventas_file_path, sep='\t')
df_ventas_orig = pd.read_csv(ventas_file_path)

# Borro columna customer_id 
#   Esta columna viene del archivo csv que agrupo valores por product_id y periodo. No sabemos si customer_id es un valor totalizado.
#   En principio no lo necesito
df_ventas = df_ventas_orig.copy()
del df_ventas['customer_id']

# -------------------------------------------------------
# Agregar Periodos faltantes con valor = 0
#    LSTM necesita toda la serie temporal en la que los productos fueron vendidos para poder predecir a futuro, incluso
#    en meses dde no hubieron ventas. Para estos meses se completa el periodo, product_id y valores a cero para tn (y demas valores tipo numericos)

# Primero convertimos la columna 'periodo' en datetime si no está en ese formato
df_ventas['periodo'] = pd.to_datetime(df_ventas['periodo'], format='%Y%m')

meses = df_ventas.periodo.unique()
prod = df_ventas.product_id.unique()

all_combinations = pd.MultiIndex.from_product([prod, meses], names=['product_id', 'periodo']).to_frame(index=False)

# Unir los datos originales con el DataFrame completo para asegurar que cada producto tenga todos los periodos
df_full = pd.merge(all_combinations, df_ventas, on=['product_id', 'periodo'], how='left')

# Rellenar los valores faltantes con ceros
df_full['tn'] = df_full['tn'].fillna(0)

df_ventas = df_full.copy()


# -------------------------------------------------------
# Agregar la col cant_periodos
#    Cant periodos indica cuantos meses hubo ventas de un product_id
# Filtrar el DataFrame para excluir los períodos donde 'tn' es cero
df_ventas_filtrado = df_ventas[df_ventas['tn'] != 0]

# Agrupar por 'product_id' y contar los períodos únicos en el DataFrame filtrado
cant_periodos = df_ventas_filtrado.groupby('product_id')['periodo'].nunique()

# Agregamos esta información al DataFrame original
df_ventas = df_ventas.merge(cant_periodos.rename('cant_periodos'), on='product_id', how='left')


# -------------------------------------------------------
# Agregamos la descripcion de cada producto (cat1, cat2, cat3, etc)
#   Esto podria ser util en caso de querer incorporar nuevas variables al modelo
df_ventas = pd.merge(df_ventas, df_productos_descripcion, on=['product_id'], how='left')

# Contar la cantidad de NaN en cada columna
cantidad_nans_por_columna = df_ventas.isna().sum()
print('\n--------------------------------------')
print('Cantidad de NaN x Columna:')
print(cantidad_nans_por_columna)

# Rellenar los valores faltantes con ceros
df_ventas = df_ventas.fillna(0)

print('\n--------------------------------------')
print('Completando a 0 los NaN')



# Contar la cantidad de NaN en cada columna
cantidad_nans_por_columna = df_ventas.isna().sum()
print('\n--------------------------------------')
print('Cantidad de NaN x Columna:')
print(cantidad_nans_por_columna)



print('\n--------------------------------------\n')
print('Generando archivo final: ../66_Datos/sell-z-780-all-LTSM.csv')

# En caso de generar el archivo a csv para uso futuro
#df_ventas.to_csv('../66_Datos/sell-z-780-all-LTSM.csv', index=False)
df_ventas.round(1).to_excel('../66_Datos/sell-z-780-all-LTSM.xlsx', index=False)

print('\n--------------------------------------')





import pandas as pd

ventas_LTSM_path = '../66_Datos/sell-z-780-all-LTSM.csv'
df_ventas = pd.read_csv(ventas_LTSM_path)

# Convertir la columna 'periodo' a tipo datetime
df_ventas['periodo'] = pd.to_datetime(df_ventas['periodo'], format='%Y-%m-%d')

# Formatear la fecha según el formato deseado
print(df_ventas.info())

df_ventas.head(2)





import pandas as pd

def calcular_total_forecast_error(actual, forecast):
    """
    Calcula el Total Forecast Error dado un DataFrame con ventas reales y pronosticadas.

    Parámetros:
    actual (pd.Series): Serie con las ventas reales.
    forecast (pd.Series): Serie con las ventas pronosticadas.

    Retorna:
    float: El Total Forecast Error.
    """
    # Calcular el error absoluto
    abs_error = abs(actual - forecast)
    
    # Calcular el Total Forecast Error
    total_forecast_error = abs_error.sum() / actual.sum()
    
    print("\n\n-----------------------------------------------------------------------------")
    print("-----------------------------------------------------------------------------")
    print(f'    >>>>>>>>>>>>       Total Forecast Error: {total_forecast_error:.2%}     <<<<<<<<<<<<<<<<<<')
    print("-----------------------------------------------------------------------------")
    print("-----------------------------------------------------------------------------\n\n")

    
    return total_forecast_error

# Ejemplo de uso
# Crear un DataFrame de ejemplo
data = {
    'product_id': [1, 2, 3, 4, 5],
    'actual_sales': [100, 150, 200, 250, 300],
    'forecast_sales': [110, 145, 190, 260, 310]
}
df = pd.DataFrame(data)

# Calcular el Total Forecast Error
tfe = calcular_total_forecast_error(df['actual_sales'], df['forecast_sales'])
#print("\n\n-----------------------------------------------------------------------------")
#print("-----------------------------------------------------------------------------")
#print(f'    >>>>>>>>>>>>       Total Forecast Error: {tfe:.2%}     <<<<<<<<<<<<<<<<<<')
#print("-----------------------------------------------------------------------------")
#print("-----------------------------------------------------------------------------\n\n")










# --------------------------------------
# Funcion nombre_file(sfx)
#   - Genera el nombre del archivo .csv con prefijo datetime YYYY-MM-DD
from datetime import datetime
def nombre_file(sfx):
    # Obtener la fecha y hora actual en el formato requerido
    current_time = datetime.now().strftime('%Y-%m-%d-%H%M-')

    # Path to output dir
    output_dir = '../666_Kaggle/Entregas/'    
    return(output_dir+current_time+sfx+'.csv')
# Indicar el nombre de la prueba
suffix_name = 'MongoAurelio' 

file_to_kaggle = nombre_file(suffix_name)
print(file_to_kaggle)


# ------------------------------------------------
# Esto va al final para escribir el archivo final

# Agrego el tfe2 al suffix del archivo
#   Calculo del total forecast error
#   tfe2 =  calcular_total_forecast_error(all_forecasts['y'], all_forecasts['yhat1'])
#    print(f'Total Forecast Error: {tfe2:.2%}')

tfe2 = 0.123456789
str_tfe2 = "_tfe2_" + str(round(tfe2, 4)) 

# Suffijo general para las dos salidas de archivos
#  Solo cambiar este valor

suffix_general = 'Sufijo-General'  + str_tfe2

# Usar la función nombre_file para asignar el nombre del archivo de salida para kaggle
suffix_to_kaagle_name = suffix_general
file_to_kaggle = nombre_file(suffix_to_kaagle_name)
# Colocar el nombre del df apropiado
#df_aGuardarEnDisco.to_csv(file_to_kaggle, index=False)

#all_forecasts.to_csv(file_to_kaggle+'all', index=False)
print(f'Predicciones ajustadas guardadas en {file_to_kaggle}')

# Fin
# ------------------------------------------------




# --------------------------------------
# Funcion nombre_file(sfx)
#   - Genera el nombre del archivo .csv con prefijo datetime YYYY-MM-DD
from datetime import datetime
def nombre_file(sfx):
    # Obtener la fecha y hora actual en el formato requerido
    current_time = datetime.now().strftime('%Y-%m-%d-%H%M-')

    # Path to output dir
    output_dir = '../666_Kaggle/Entregas/'    
    return(output_dir+current_time+sfx+'.csv')

# Indicar el nombre de la prueba


# Agrego el tfe2 al suffix del archivo
#   Calculo del total forecast error
#   tfe2 =  calcular_total_forecast_error(all_forecasts['y'], all_forecasts['yhat1'])
#    print(f'Total Forecast Error: {tfe2:.2%}')

tfe2 = 0.123456789
str_tfe2 = "_tfe2_" + str(round(tfe2, 4)) 

suffix_name = 'MongoAurelio' + str_tfe2
file_to_kaggle = nombre_file(suffix_name)
print(file_to_kaggle)
# --------------------------------------






import pandas as pd

# Cargar los datos de ventas y productos a predecir
ventas_file_path = '../66_Datos/sell-in.txt'
productos_file_path = '../66_Datos/productos_a_predecir.txt'
productos_descripcion = '../66_Datos/tb_productos_descripcion.txt'

df_productos_descripcion = pd.read_csv(productos_descripcion, sep='\t')
df_productos_descripcion = df_productos_descripcion[['product_id', 'cat1', 'cat2', 'cat3', 'brand', 'sku_size', 'descripcion']]
df_productos_descripcion = df_productos_descripcion.reset_index(drop=True)
# Nota: no encuentro duplicados en productos_descripcion. De todas formas armo la sentencia de eliminarlos ya que pueden aparecer
#       futuras versiones del archivo
# Eliminar los duplicados en la columna 'product_id', manteniendo solo la primera aparición
df_productos_descripcion.drop_duplicates(subset='product_id', keep='first', inplace=True)

df_ventas_orig = pd.read_csv(ventas_file_path, sep='\t')

df_ventas = pd.merge(df_ventas_orig, df_productos_descripcion, on=['product_id'], how='left')


df_productos = pd.read_csv(productos_file_path, sep='\t')


# Filtrar las ventas para que solo incluya los productos a predecir
productos_a_predecir = df_productos['product_id'].unique()
sell_780_all = df_ventas[df_ventas['product_id'].isin(productos_a_predecir)]


sell_780_groupBy_Periodo_ProdId = sell_780_all.groupby(['periodo', 'product_id'], as_index=False).sum()

# Opcional: Guardar el DataFrame filtrado en un archivo CSV
#df['ds'] = pd.to_datetime(df['periodo'], format='%Y%m')
df_ventas_toCsv = df_ventas
df_ventas_toCsv['periodo'] = pd.to_datetime(df_ventas_toCsv['periodo'], format='%Y%m')






# Generar CSVs 
df_ventas_toCsv.to_csv('../66_Datos/sell-in.csv', index=False)
sell_780_all.to_csv('../66_Datos/sell-z-780-all-prodId.csv', index=False)
sell_780_groupBy_Periodo_ProdId.to_csv('../66_Datos/sell-z-780-groupBy-Period-ProdId.csv', index=False)


df_productos_descripcion = df_productos_descripcion[['product_id', 'cat1', 'cat2', 'cat3', 'brand', 'sku_size', 'descripcion']]
df_productos_descripcion = df_productos_descripcion.reset_index(drop=True)

# Nota: no encuentro duplicados en productos_descripcion. De todas formas armo la sentencia de eliminarlos ya que pueden aparecer
#       futuras versiones del archivo
# Eliminar los duplicados en la columna 'product_id', manteniendo solo la primera aparición
df_productos_descripcion.drop_duplicates(subset='product_id', keep='first', inplace=True)


df1 = pd.merge(df_ventas, df_productos_descripcion, on=['product_id'], how='left')



# CSV de las ventas de todos los 780 con el campo periodo convertido a datetime
#   Este archivo lo uso en Orange y nec que periodo tenga formato fecha
sell_780_all_toDatetime_toCsv = sell_780_all.copy()
sell_780_all_toDatetime_toCsv['periodo'] = pd.to_datetime(sell_780_all_toDatetime_toCsv['periodo'], format='%Y%m')
sell_780_all_toDatetime_toCsv.to_csv('../66_Datos/sell-z-780-all-prodId-toDatetime.csv', index=False)


sell_780_all.loc[(sell_780_all['product_id'] == 20001) & (sell_780_all['periodo'] == 201701)].head(5)





import pandas as pd

# Cargar los datos de ventas y productos a predecir
ventas_file_path = '../66_Datos/sell-in.txt'
productos_file_path = '../66_Datos/productos_a_predecir-39.txt'

df_ventas = pd.read_csv(ventas_file_path, sep='\t')
df_productos = pd.read_csv(productos_file_path, sep='\t')

# Filtrar las ventas para que solo incluya los productos a predecir
productos_a_predecir = df_productos['product_id'].unique()
sell_39_all = df_ventas[df_ventas['product_id'].isin(productos_a_predecir)]


sell_39_groupBy_Periodo_ProdId = sell_39_all.groupby(['periodo', 'product_id'], as_index=False).sum()

# Opcional: Guardar el DataFrame filtrado en un archivo CSV
sell_39_all.to_csv('../66_Datos/sell-z-39-all-prodId.csv', index=False)
sell_39_groupBy_Periodo_ProdId.to_csv('../66_Datos/sell-z-39-groupBy-Period-ProdId.csv', index=False)





from ydata_profiling import ProfileReport

ventas_LTSM_path = './66_Datos/sell-z-780-all-LTSM.csv'
df_ventas = pd.read_csv(ventas_LTSM_path)

profile = ProfileReport(df_ventas, tsmode=False, title="Profiling Report")

profile.to_file("./EDA_ydataProfiling/eda-yprof.html")

profile = ProfileReport(df_ventas, tsmode=True, title="Profiling Report")

profile.to_file("./EDA_ydataProfiling/eda-yprof-ts.html")





print(range(2021, 2030))


import pandas as pd
import numpy as np

# Crear un DataFrame con fechas desde 2021 hasta 2039
f2 = pd.DataFrame({
    'ds': pd.to_datetime([str(x) for x in range(2021, 2040)], format='%Y'),
    'y': np.nan
})

print(f2)


f2


import pandas as pd
import numpy as np

# 2021 a 2090
futuro = pd.DataFrame({
    'ds': pd.to_datetime([x for x in range(2021, 2025)], format='%Y'),
    'y': np.nan
})


futuro


pd.to_datetime([x for x in range(2021, 2025)], format='%Y')








import pandas as pd

# Cargar los datos de ventas y productos a predecir
ventas_file_path = '../66_Datos/sell-in.txt'
productos_file_path = '../66_Datos/productos_a_predecir.txt'
productos_descripcion = '../66_Datos/tb_productos_descripcion.txt'


# tb_productos_descripcion.txt es la ultima tabla (2024/06/15) que presento con las caracteristicas y categoria de cada producto
df_productos_descripcion = pd.read_csv(productos_descripcion, sep='\t')
df_productos_descripcion = df_productos_descripcion[['product_id', 'cat1', 'cat2', 'cat3', 'brand', 'sku_size', 'descripcion']]
df_productos_descripcion = df_productos_descripcion.reset_index(drop=True)
# Nota: no encuentro duplicados en productos_descripcion. De todas formas armo la sentencia de eliminarlos ya que pueden aparecer
#       futuras versiones del archivo
# Eliminar los duplicados en la columna 'product_id', manteniendo solo la primera aparición
df_productos_descripcion.drop_duplicates(subset='product_id', keep='first', inplace=True)

df_ventas_orig = pd.read_csv(ventas_file_path, sep='\t')

df_ventas = pd.merge(df_ventas_orig, df_productos_descripcion, on=['product_id'], how='left')

# Cargamos los productos a predecir (780)
df_productos = pd.read_csv(productos_file_path, sep='\t')


# Filtrar las ventas para que solo incluya los productos a predecir. Va .unique() 
productos_a_predecir = df_productos['product_id'].unique()

# Agregar la columna "en780" a df_ventas
df_ventas['en780'] = df_ventas['product_id'].apply(lambda x: 1 if x in productos_a_predecir else 0)

# Agregar columna `cant_periodos`
# Primero convertimos la columna 'periodo' en datetime si no está en ese formato
df_ventas['periodo'] = pd.to_datetime(df_ventas['periodo'], format='%Y%m')

# Agrupamos por 'product_id' y contamos los periodos únicos
cant_periodos = df_ventas.groupby('product_id')['periodo'].nunique()

# Agregamos esta información al DataFrame original
df_ventas = df_ventas.merge(cant_periodos.rename('cant_periodos'), on='product_id', how='left')






# Verificar si hay valores nulos en cat1, cat2, cat3, brand, sku_size, descripcion
nulos_cat1 = df_ventas['cat1'].isnull().sum()
nulos_cat2 = df_ventas['cat2'].isnull().sum()
nulos_cat3 = df_ventas['cat3'].isnull().sum()
nulos_brand = df_ventas['brand'].isnull().sum()
nulos_sku_size = df_ventas['sku_size'].isnull().sum()
nulos_descripcion = df_ventas['descripcion'].isnull().sum()

print(f'Valores nulos en cat1: {nulos_cat1}')
print(f'Valores nulos en cat2: {nulos_cat2}')
print(f'Valores nulos en cat3: {nulos_cat3}')
print(f'Valores nulos en brand: {nulos_brand}')
print(f'Valores nulos en sku_size: {nulos_sku_size}')
print(f'Valores nulos en descripcion: {nulos_descripcion}')


# Reemplazar valores nulos en columnas tipo object con "sinCatego"
cols_object = ['cat1', 'cat2', 'cat3', 'brand', 'descripcion']
for col in cols_object:
    df_ventas[col].fillna('sinCatego', inplace=True)

# Reemplazar valores nulos en columnas numéricas con 0
cols_numeric = ['sku_size']
for col in cols_numeric:
    df_ventas[col].fillna(0, inplace=True)


# Verificar si hay valores nulos en cat1, cat2, cat3, brand, sku_size, descripcion
nulos_cat1 = df_ventas['cat1'].isnull().sum()
nulos_cat2 = df_ventas['cat2'].isnull().sum()
nulos_cat3 = df_ventas['cat3'].isnull().sum()
nulos_brand = df_ventas['brand'].isnull().sum()
nulos_sku_size = df_ventas['sku_size'].isnull().sum()
nulos_descripcion = df_ventas['descripcion'].isnull().sum()

print(f'Valores nulos en cat1: {nulos_cat1}')
print(f'Valores nulos en cat2: {nulos_cat2}')
print(f'Valores nulos en cat3: {nulos_cat3}')
print(f'Valores nulos en brand: {nulos_brand}')
print(f'Valores nulos en sku_size: {nulos_sku_size}')
print(f'Valores nulos en descripcion: {nulos_descripcion}')


print('--------------------------------------')
print('--------------------------------------')



# Filtrar los productos en df_ventas donde cat1 es 'sinCatego'
productos_sin_categoria = df_ventas[df_ventas['cat1'] == 'sinCatego']['product_id'].unique()

# Encontrar los product_id que faltan en df_productos_descripcion
productos_descripcion_ids = df_productos_descripcion['product_id'].unique()
productos_faltantes = set(productos_sin_categoria) - set(productos_descripcion_ids)

# Mostrar los product_id que faltan en df_productos_descripcion
print('Product IDs que faltan en df_productos_descripcion:')
print(productos_faltantes)


print('--------------------------------------')
print('--------------------------------------')


# Crear un DataFrame con los productos faltantes
productos_faltantes_df = pd.DataFrame({
    'product_id': list(productos_faltantes),
    'cat1': 'sinCatego',
    'cat2': 'sinCatego',
    'cat3': 'sinCatego',
    'brand': 'sinCatego',
    'sku_size': 0,
    'descripcion': 'sinCatego'
})

# Concatenar el DataFrame de productos faltantes con df_productos_descripcion
df_productos_descripcion_completo = pd.concat([df_productos_descripcion, productos_faltantes_df], ignore_index=True)

# Verificar el resultado
print(df_productos_descripcion_completo)



# Opcional: Guardar el DataFrame filtrado en un archivo CSV
#df['ds'] = pd.to_datetime(df['periodo'], format='%Y%m')
df_ventas_toCsv = df_ventas
#df_ventas_toCsv['periodo'] = pd.to_datetime(df_ventas_toCsv['periodo'], format='%Y%m')

# Genero el csv para crear en pg z_l3.sell_all
df_ventas_toCsv.to_csv('../66_Datos/sell-in-all-to-postgres.csv', index=False)


# Genero el csv para crear en pg z_l3.productos2
df_productos_descripcion_completo.to_csv('../66_Datos/tb_productos_descripcion_ac.csv', index=False)



df_ventas.loc[df_ventas.product_id == 20808].head()






